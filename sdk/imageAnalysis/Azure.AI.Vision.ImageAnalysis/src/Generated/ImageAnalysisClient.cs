// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using Azure;
using Azure.Core;
using Azure.Core.Pipeline;

namespace Azure.AI.Vision.ImageAnalysis
{
    // Data plane generated client.
    /// <summary> The ImageAnalysis service client. </summary>
    public partial class ImageAnalysisClient
    {
        private const string AuthorizationHeader = "Ocp-Apim-Subscription-Key";
        private readonly AzureKeyCredential _keyCredential;
        private readonly HttpPipeline _pipeline;
        private readonly Uri _endpoint;
        private readonly string _apiVersion;

        /// <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        internal ClientDiagnostics ClientDiagnostics { get; }

        /// <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        public virtual HttpPipeline Pipeline => _pipeline;

        /// <summary> Initializes a new instance of ImageAnalysisClient for mocking. </summary>
        protected ImageAnalysisClient()
        {
        }

        /// <summary> Initializes a new instance of ImageAnalysisClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://&lt;resource-name&gt;.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public ImageAnalysisClient(Uri endpoint, AzureKeyCredential credential) : this(endpoint, credential, new ImageAnalysisClientOptions())
        {
        }

        /// <summary> Initializes a new instance of ImageAnalysisClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://&lt;resource-name&gt;.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public ImageAnalysisClient(Uri endpoint, AzureKeyCredential credential, ImageAnalysisClientOptions options)
        {
            Argument.AssertNotNull(endpoint, nameof(endpoint));
            Argument.AssertNotNull(credential, nameof(credential));
            options ??= new ImageAnalysisClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _keyCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new AzureKeyCredentialPolicy(_keyCredential, AuthorizationHeader) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Performs a single Image Analysis operation. </summary>
        /// <param name="imageContents"> The image to be analyzed. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContents"/> is null. </exception>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeStreamAsync(BinaryData,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)']/*" />
        public virtual async Task<Response<ImageAnalysisResult>> AnalyzeStreamAsync(BinaryData imageContents, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(imageContents, nameof(imageContents));

            RequestContext context = FromCancellationToken(cancellationToken);
            Response response = await AnalyzeStreamAsync(imageContents, visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context).ConfigureAwait(false);
            return Response.FromValue(ImageAnalysisResult.FromResponse(response), response);
        }

        /// <summary> Performs a single Image Analysis operation. </summary>
        /// <param name="imageContents"> The image to be analyzed. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContents"/> is null. </exception>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeStream(BinaryData,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)']/*" />
        public virtual Response<ImageAnalysisResult> AnalyzeStream(BinaryData imageContents, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(imageContents, nameof(imageContents));

            RequestContext context = FromCancellationToken(cancellationToken);
            Response response = AnalyzeStream(imageContents, visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context);
            return Response.FromValue(ImageAnalysisResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Performs a single Image Analysis operation
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="AnalyzeStreamAsync(BinaryData,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeStreamAsync(RequestContent,IEnumerable{VisualFeatures},string,string,string,bool?,RequestContext)']/*" />
        public virtual async Task<Response> AnalyzeStreamAsync(RequestContent content, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("ImageAnalysisClient.AnalyzeStream");
            scope.Start();
            try
            {
                using HttpMessage message = CreateAnalyzeStreamRequest(content, visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Performs a single Image Analysis operation
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="AnalyzeStream(BinaryData,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeStream(RequestContent,IEnumerable{VisualFeatures},string,string,string,bool?,RequestContext)']/*" />
        public virtual Response AnalyzeStream(RequestContent content, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("ImageAnalysisClient.AnalyzeStream");
            scope.Start();
            try
            {
                using HttpMessage message = CreateAnalyzeStreamRequest(content, visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Performs a single Image Analysis operation. </summary>
        /// <param name="imageContents"> The image to be analyzed. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContents"/> is null. </exception>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeUrlAsync(ImageUrl,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)']/*" />
        public virtual async Task<Response<ImageAnalysisResult>> AnalyzeUrlAsync(ImageUrl imageContents, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(imageContents, nameof(imageContents));

            RequestContext context = FromCancellationToken(cancellationToken);
            Response response = await AnalyzeUrlAsync(imageContents.ToRequestContent(), visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context).ConfigureAwait(false);
            return Response.FromValue(ImageAnalysisResult.FromResponse(response), response);
        }

        /// <summary> Performs a single Image Analysis operation. </summary>
        /// <param name="imageContents"> The image to be analyzed. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContents"/> is null. </exception>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeUrl(ImageUrl,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)']/*" />
        public virtual Response<ImageAnalysisResult> AnalyzeUrl(ImageUrl imageContents, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(imageContents, nameof(imageContents));

            RequestContext context = FromCancellationToken(cancellationToken);
            Response response = AnalyzeUrl(imageContents.ToRequestContent(), visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context);
            return Response.FromValue(ImageAnalysisResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Performs a single Image Analysis operation
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="AnalyzeUrlAsync(ImageUrl,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeUrlAsync(RequestContent,IEnumerable{VisualFeatures},string,string,string,bool?,RequestContext)']/*" />
        public virtual async Task<Response> AnalyzeUrlAsync(RequestContent content, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("ImageAnalysisClient.AnalyzeUrl");
            scope.Start();
            try
            {
                using HttpMessage message = CreateAnalyzeUrlRequest(content, visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Performs a single Image Analysis operation
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="AnalyzeUrl(ImageUrl,IEnumerable{VisualFeatures},string,string,string,bool?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="visualFeatures"> A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include: Categories, Tags, Description, Faces, ImageType, Color, Adult, Brands, Objects, and Celebrities. If VisualFeatures is not specified, then Categories, Tags, and Description are included in the response by default. </param>
        /// <param name="modelName"> The name of the custom trained model. This parameter needs to be specified if the parameter "features" is not specified. </param>
        /// <param name="language"> The desired language for output generation. If this parameter is not specified, the default value is "en". See https://aka.ms/cv-languages for a list of supported languages. </param>
        /// <param name="smartCropsAspectRatios"> A list of aspect ratios to use for smartCrops feature. Aspect ratios are calculated by dividing the target crop width by the height. Supported values are between 0.75 and 1.8 (inclusive). Multiple values should be comma-separated. If this parameter is not specified, the service will return one crop suggestion with an aspect ratio it sees fit between 0.5 and 2.0 (inclusive). </param>
        /// <param name="genderNeutralCaption"> Boolean flag for enabling gender-neutral captioning for caption and denseCaptions features. If this parameter is not specified, the default value is "false". </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/ImageAnalysisClient.xml" path="doc/members/member[@name='AnalyzeUrl(RequestContent,IEnumerable{VisualFeatures},string,string,string,bool?,RequestContext)']/*" />
        public virtual Response AnalyzeUrl(RequestContent content, IEnumerable<VisualFeatures> visualFeatures = null, string modelName = null, string language = null, string smartCropsAspectRatios = null, bool? genderNeutralCaption = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("ImageAnalysisClient.AnalyzeUrl");
            scope.Start();
            try
            {
                using HttpMessage message = CreateAnalyzeUrlRequest(content, visualFeatures, modelName, language, smartCropsAspectRatios, genderNeutralCaption, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        internal HttpMessage CreateAnalyzeStreamRequest(RequestContent content, IEnumerable<VisualFeatures> visualFeatures, string modelName, string language, string smartCropsAspectRatios, bool? genderNeutralCaption, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendRaw("/computervision", false);
            uri.AppendPath("/imageanalysis:analyze", false);
            uri.AppendQuery("overload", "stream", true);
            uri.AppendQuery("api-version", _apiVersion, true);
            if (visualFeatures != null && Optional.IsCollectionDefined(visualFeatures))
            {
                uri.AppendQueryDelimited("features", visualFeatures, ",", true);
            }
            if (modelName != null)
            {
                uri.AppendQuery("model-name", modelName, true);
            }
            if (language != null)
            {
                uri.AppendQuery("langauge", language, true);
            }
            if (smartCropsAspectRatios != null)
            {
                uri.AppendQuery("smartcrops-aspect-ratios", smartCropsAspectRatios, true);
            }
            if (genderNeutralCaption != null)
            {
                uri.AppendQuery("gender-neutral-caption", genderNeutralCaption.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/octet-stream");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateAnalyzeUrlRequest(RequestContent content, IEnumerable<VisualFeatures> visualFeatures, string modelName, string language, string smartCropsAspectRatios, bool? genderNeutralCaption, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendRaw("/computervision", false);
            uri.AppendPath("/imageanalysis:analyze", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            if (visualFeatures != null && Optional.IsCollectionDefined(visualFeatures))
            {
                uri.AppendQueryDelimited("features", visualFeatures, ",", true);
            }
            if (modelName != null)
            {
                uri.AppendQuery("model-name", modelName, true);
            }
            if (language != null)
            {
                uri.AppendQuery("langauge", language, true);
            }
            if (smartCropsAspectRatios != null)
            {
                uri.AppendQuery("smartcrops-aspect-ratios", smartCropsAspectRatios, true);
            }
            if (genderNeutralCaption != null)
            {
                uri.AppendQuery("gender-neutral-caption", genderNeutralCaption.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        private static RequestContext DefaultRequestContext = new RequestContext();
        internal static RequestContext FromCancellationToken(CancellationToken cancellationToken = default)
        {
            if (!cancellationToken.CanBeCanceled)
            {
                return DefaultRequestContext;
            }

            return new RequestContext() { CancellationToken = cancellationToken };
        }

        private static ResponseClassifier _responseClassifier200;
        private static ResponseClassifier ResponseClassifier200 => _responseClassifier200 ??= new StatusCodeClassifier(stackalloc ushort[] { 200 });
    }
}
