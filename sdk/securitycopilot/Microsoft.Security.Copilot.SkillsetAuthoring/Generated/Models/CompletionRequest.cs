// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using Azure.Core;

namespace Microsoft.Security.Copilot.SkillsetAuthoring.Models
{
    /// <summary> The CompletionRequest. </summary>
    public partial class CompletionRequest : BaseCompletionRequest
    {
        /// <summary> Initializes a new instance of CompletionRequest. </summary>
        /// <param name="stop"> Stop sequences to terminate generation. </param>
        /// <param name="logitBias"> Adjusts likelihood of specific tokens. </param>
        /// <param name="responseFormat"> The response format specification. </param>
        /// <param name="prompt"></param>
        /// <exception cref="ArgumentNullException"> <paramref name="stop"/>, <paramref name="logitBias"/>, <paramref name="responseFormat"/> or <paramref name="prompt"/> is null. </exception>
        public CompletionRequest(IEnumerable<string> stop, IReadOnlyDictionary<string, int> logitBias, BinaryData responseFormat, string prompt) : base(stop, logitBias, responseFormat)
        {
            Argument.AssertNotNull(stop, nameof(stop));
            Argument.AssertNotNull(logitBias, nameof(logitBias));
            Argument.AssertNotNull(responseFormat, nameof(responseFormat));
            Argument.AssertNotNull(prompt, nameof(prompt));

            Prompt = prompt;
        }

        /// <summary> Initializes a new instance of CompletionRequest. </summary>
        /// <param name="maxTokens"> The maximum number of tokens to generate. </param>
        /// <param name="temperature"> The sampling temperature to use. </param>
        /// <param name="topP"> The nucleus sampling parameter. </param>
        /// <param name="n"> The number of completions to generate. </param>
        /// <param name="stream"> Specifies whether to stream the response. </param>
        /// <param name="logprobs"> The number of log probabilities to include. </param>
        /// <param name="echo"> Whether to include the prompt in the output. </param>
        /// <param name="stop"> Stop sequences to terminate generation. </param>
        /// <param name="presencePenalty"> The penalty for repeating words in the presence. </param>
        /// <param name="frequencyPenalty"> The penalty for repeating tokens. </param>
        /// <param name="bestOf"> The number of completions to choose the best from. </param>
        /// <param name="logitBias"> Adjusts likelihood of specific tokens. </param>
        /// <param name="responseFormat"> The response format specification. </param>
        /// <param name="prompt"></param>
        internal CompletionRequest(int? maxTokens, double? temperature, double? topP, int? n, bool? stream, int? logprobs, bool? echo, IReadOnlyList<string> stop, double? presencePenalty, double? frequencyPenalty, int? bestOf, IReadOnlyDictionary<string, int> logitBias, BinaryData responseFormat, string prompt) : base(maxTokens, temperature, topP, n, stream, logprobs, echo, stop, presencePenalty, frequencyPenalty, bestOf, logitBias, responseFormat)
        {
            Prompt = prompt;
        }

        /// <summary> Gets the prompt. </summary>
        public string Prompt { get; }
    }
}
