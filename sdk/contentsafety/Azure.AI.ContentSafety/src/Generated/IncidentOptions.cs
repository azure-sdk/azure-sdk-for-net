// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System.Collections.Generic;
using Azure.Core;

namespace Azure.AI.ContentSafety
{
    /// <summary> The text analysis request. </summary>
    public partial class IncidentOptions
    {
        /// <summary> Initializes a new instance of <see cref="IncidentOptions"/>. </summary>
        public IncidentOptions()
        {
            IncidentNames = new ChangeTrackingList<string>();
        }

        /// <summary> Initializes a new instance of <see cref="IncidentOptions"/>. </summary>
        /// <param name="incidentNames"> The accept decision made by service. </param>
        /// <param name="haltOnIncidentHit"> When set to true, further analyses of harmful content will not be performed in cases where incidents are hit. When set to false, all analyses of harmful content will be performed, whether or not incidents are hit. </param>
        internal IncidentOptions(IList<string> incidentNames, bool? haltOnIncidentHit)
        {
            IncidentNames = incidentNames;
            HaltOnIncidentHit = haltOnIncidentHit;
        }

        /// <summary> The accept decision made by service. </summary>
        public IList<string> IncidentNames { get; }
        /// <summary> When set to true, further analyses of harmful content will not be performed in cases where incidents are hit. When set to false, all analyses of harmful content will be performed, whether or not incidents are hit. </summary>
        public bool? HaltOnIncidentHit { get; set; }
    }
}
