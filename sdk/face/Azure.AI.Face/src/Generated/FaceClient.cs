// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using Azure;
using Azure.Core;
using Azure.Core.Pipeline;

namespace Azure.AI.Face
{
    // Data plane generated client.
    /// <summary> The Face service client. </summary>
    public partial class FaceClient
    {
        private const string AuthorizationHeader = "Ocp-Apim-Subscription-Key";
        private readonly AzureKeyCredential _keyCredential;
        private static readonly string[] AuthorizationScopes = new string[] { "https://cognitiveservices.azure.com/.default" };
        private readonly TokenCredential _tokenCredential;
        private readonly HttpPipeline _pipeline;
        private readonly Uri _endpoint;
        private readonly string _apiVersion;

        /// <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        internal ClientDiagnostics ClientDiagnostics { get; }

        /// <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        public virtual HttpPipeline Pipeline => _pipeline;

        /// <summary> Initializes a new instance of FaceClient for mocking. </summary>
        protected FaceClient()
        {
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://&lt;resource-name&gt;.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, AzureKeyCredential credential) : this(endpoint, credential, new FaceClientOptions())
        {
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://&lt;resource-name&gt;.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, TokenCredential credential) : this(endpoint, credential, new FaceClientOptions())
        {
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://&lt;resource-name&gt;.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, AzureKeyCredential credential, FaceClientOptions options)
        {
            if (endpoint == null)
            {
                throw new ArgumentNullException(nameof(endpoint));
            }
            if (credential == null)
            {
                throw new ArgumentNullException(nameof(credential));
            }
            options ??= new FaceClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _keyCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new AzureKeyCredentialPolicy(_keyCredential, AuthorizationHeader) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://&lt;resource-name&gt;.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, TokenCredential credential, FaceClientOptions options)
        {
            if (endpoint == null)
            {
                throw new ArgumentNullException(nameof(endpoint));
            }
            if (credential == null)
            {
                throw new ArgumentNullException(nameof(credential));
            }
            options ??= new FaceClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _tokenCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new BearerTokenAuthenticationPolicy(_tokenCredential, AuthorizationScopes) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="url"> URL of input image. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="url"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrlAsync(Uri,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceDetectionResult>>> DetectFromUrlAsync(Uri url, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, RecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, DetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            if (url == null)
            {
                throw new ArgumentNullException(nameof(url));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            DetectFromUrlRequest detectFromUrlRequest = new DetectFromUrlRequest(url);
            Response response = await DetectFromUrlAsync(detectFromUrlRequest.ToRequestContent(), returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context).ConfigureAwait(false);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="url"> URL of input image. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="url"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrl(Uri,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceDetectionResult>> DetectFromUrl(Uri url, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, RecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, DetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            if (url == null)
            {
                throw new ArgumentNullException(nameof(url));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            DetectFromUrlRequest detectFromUrlRequest = new DetectFromUrlRequest(url);
            Response response = DetectFromUrl(detectFromUrlRequest.ToRequestContent(), returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectFromUrlAsync(Uri,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrlAsync(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual async Task<Response> DetectFromUrlAsync(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.DetectFromUrl");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectFromUrlRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectFromUrl(Uri,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrl(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual Response DetectFromUrl(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.DetectFromUrl");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectFromUrlRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="imageContent"> The image to be analyzed. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContent"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromStreamAsync(BinaryData,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceDetectionResult>>> DetectFromStreamAsync(BinaryData imageContent, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, RecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, DetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            if (imageContent == null)
            {
                throw new ArgumentNullException(nameof(imageContent));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            using RequestContent content = imageContent;
            Response response = await DetectFromStreamAsync(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context).ConfigureAwait(false);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="imageContent"> The image to be analyzed. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContent"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromStream(BinaryData,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceDetectionResult>> DetectFromStream(BinaryData imageContent, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, RecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, DetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            if (imageContent == null)
            {
                throw new ArgumentNullException(nameof(imageContent));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            using RequestContent content = imageContent;
            Response response = DetectFromStream(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectFromStreamAsync(BinaryData,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromStreamAsync(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual async Task<Response> DetectFromStreamAsync(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.DetectFromStream");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectFromStreamRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectFromStream(BinaryData,bool?,bool?,string,RecognitionModel?,bool?,DetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromStream(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual Response DetectFromStream(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.DetectFromStream");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectFromStreamRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a faceId array, a face list or a large face list. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="faceIds"> An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="faceIds"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarAsync(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FindSimilarResult>>> FindSimilarAsync(string faceId, IEnumerable<string> faceIds, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            if (faceId == null)
            {
                throw new ArgumentNullException(nameof(faceId));
            }
            if (faceIds == null)
            {
                throw new ArgumentNullException(nameof(faceIds));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarRequest findSimilarRequest = new FindSimilarRequest(faceId, faceIds.ToList())
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = await FindSimilarAsync(findSimilarRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FindSimilarResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FindSimilarResult> array = new List<FindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FindSimilarResult.DeserializeFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a faceId array, a face list or a large face list. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="faceIds"> An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="faceIds"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilar(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FindSimilarResult>> FindSimilar(string faceId, IEnumerable<string> faceIds, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            if (faceId == null)
            {
                throw new ArgumentNullException(nameof(faceId));
            }
            if (faceIds == null)
            {
                throw new ArgumentNullException(nameof(faceIds));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarRequest findSimilarRequest = new FindSimilarRequest(faceId, faceIds.ToList())
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = FindSimilar(findSimilarRequest.ToRequestContent(), context);
            IReadOnlyList<FindSimilarResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FindSimilarResult> array = new List<FindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FindSimilarResult.DeserializeFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a faceId array, a face list or a large face list.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilarAsync(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> FindSimilarAsync(RequestContent content, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilar");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a faceId array, a face list or a large face list.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilar(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilar(RequestContent,RequestContext)']/*" />
        public virtual Response FindSimilar(RequestContent content, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilar");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Verify whether two faces belong to a same person or whether one face belongs to a person. </summary>
        /// <param name="faceId1"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="faceId2"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId1"/> or <paramref name="faceId2"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyAsync(string,string,CancellationToken)']/*" />
        public virtual async Task<Response<VerifyResult>> VerifyAsync(string faceId1, string faceId2, CancellationToken cancellationToken = default)
        {
            if (faceId1 == null)
            {
                throw new ArgumentNullException(nameof(faceId1));
            }
            if (faceId2 == null)
            {
                throw new ArgumentNullException(nameof(faceId2));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyRequest verifyRequest = new VerifyRequest(faceId1, faceId2);
            Response response = await VerifyAsync(verifyRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(VerifyResult.FromResponse(response), response);
        }

        /// <summary> Verify whether two faces belong to a same person or whether one face belongs to a person. </summary>
        /// <param name="faceId1"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="faceId2"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId1"/> or <paramref name="faceId2"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Verify(string,string,CancellationToken)']/*" />
        public virtual Response<VerifyResult> Verify(string faceId1, string faceId2, CancellationToken cancellationToken = default)
        {
            if (faceId1 == null)
            {
                throw new ArgumentNullException(nameof(faceId1));
            }
            if (faceId2 == null)
            {
                throw new ArgumentNullException(nameof(faceId2));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyRequest verifyRequest = new VerifyRequest(faceId1, faceId2);
            Response response = Verify(verifyRequest.ToRequestContent(), context);
            return Response.FromValue(VerifyResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Verify whether two faces belong to a same person or whether one face belongs to a person.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyAsync(string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> VerifyAsync(RequestContent content, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Verify");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Verify whether two faces belong to a same person or whether one face belongs to a person.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="Verify(string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Verify(RequestContent,RequestContext)']/*" />
        public virtual Response Verify(RequestContent content, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Verify");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Divide candidate faces into groups based on face similarity. </summary>
        /// <param name="faceIds"> Array of candidate faceId created by Face - Detect. The maximum is 1000 faces. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='GroupAsync(IEnumerable{string},CancellationToken)']/*" />
        public virtual async Task<Response<GroupResult>> GroupAsync(IEnumerable<string> faceIds, CancellationToken cancellationToken = default)
        {
            if (faceIds == null)
            {
                throw new ArgumentNullException(nameof(faceIds));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            GroupRequest groupRequest = new GroupRequest(faceIds.ToList());
            Response response = await GroupAsync(groupRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(GroupResult.FromResponse(response), response);
        }

        /// <summary> Divide candidate faces into groups based on face similarity. </summary>
        /// <param name="faceIds"> Array of candidate faceId created by Face - Detect. The maximum is 1000 faces. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> is null. </exception>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Group(IEnumerable{string},CancellationToken)']/*" />
        public virtual Response<GroupResult> Group(IEnumerable<string> faceIds, CancellationToken cancellationToken = default)
        {
            if (faceIds == null)
            {
                throw new ArgumentNullException(nameof(faceIds));
            }

            RequestContext context = FromCancellationToken(cancellationToken);
            GroupRequest groupRequest = new GroupRequest(faceIds.ToList());
            Response response = Group(groupRequest.ToRequestContent(), context);
            return Response.FromValue(GroupResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Divide candidate faces into groups based on face similarity.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="GroupAsync(IEnumerable{string},CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='GroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> GroupAsync(RequestContent content, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Group");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Divide candidate faces into groups based on face similarity.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="Group(IEnumerable{string},CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Group(RequestContent,RequestContext)']/*" />
        public virtual Response Group(RequestContent content, RequestContext context = null)
        {
            if (content == null)
            {
                throw new ArgumentNullException(nameof(content));
            }

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Group");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        private FaceLists _cachedFaceLists;
        private LargeFaceLists _cachedLargeFaceLists;
        private FaceAsync _cachedFaceAsync;
        private PersonDirectoryPersons _cachedPersonDirectoryPersons;
        private PersonDirectoryDynamicPersonGroups _cachedPersonDirectoryDynamicPersonGroups;
        private PersonGroups _cachedPersonGroups;
        private LargePersonGroups _cachedLargePersonGroups;
        private LivenessSessions _cachedLivenessSessions;
        private LivenessWithVerifySessions _cachedLivenessWithVerifySessions;

        /// <summary> Initializes a new instance of FaceLists. </summary>
        public virtual FaceLists GetFaceListsClient()
        {
            return Volatile.Read(ref _cachedFaceLists) ?? Interlocked.CompareExchange(ref _cachedFaceLists, new FaceLists(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedFaceLists;
        }

        /// <summary> Initializes a new instance of LargeFaceLists. </summary>
        public virtual LargeFaceLists GetLargeFaceListsClient()
        {
            return Volatile.Read(ref _cachedLargeFaceLists) ?? Interlocked.CompareExchange(ref _cachedLargeFaceLists, new LargeFaceLists(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedLargeFaceLists;
        }

        /// <summary> Initializes a new instance of FaceAsync. </summary>
        public virtual FaceAsync GetFaceAsyncClient()
        {
            return Volatile.Read(ref _cachedFaceAsync) ?? Interlocked.CompareExchange(ref _cachedFaceAsync, new FaceAsync(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedFaceAsync;
        }

        /// <summary> Initializes a new instance of PersonDirectoryPersons. </summary>
        public virtual PersonDirectoryPersons GetPersonDirectoryPersonsClient()
        {
            return Volatile.Read(ref _cachedPersonDirectoryPersons) ?? Interlocked.CompareExchange(ref _cachedPersonDirectoryPersons, new PersonDirectoryPersons(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedPersonDirectoryPersons;
        }

        /// <summary> Initializes a new instance of PersonDirectoryDynamicPersonGroups. </summary>
        public virtual PersonDirectoryDynamicPersonGroups GetPersonDirectoryDynamicPersonGroupsClient()
        {
            return Volatile.Read(ref _cachedPersonDirectoryDynamicPersonGroups) ?? Interlocked.CompareExchange(ref _cachedPersonDirectoryDynamicPersonGroups, new PersonDirectoryDynamicPersonGroups(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedPersonDirectoryDynamicPersonGroups;
        }

        /// <summary> Initializes a new instance of PersonGroups. </summary>
        public virtual PersonGroups GetPersonGroupsClient()
        {
            return Volatile.Read(ref _cachedPersonGroups) ?? Interlocked.CompareExchange(ref _cachedPersonGroups, new PersonGroups(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedPersonGroups;
        }

        /// <summary> Initializes a new instance of LargePersonGroups. </summary>
        public virtual LargePersonGroups GetLargePersonGroupsClient()
        {
            return Volatile.Read(ref _cachedLargePersonGroups) ?? Interlocked.CompareExchange(ref _cachedLargePersonGroups, new LargePersonGroups(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedLargePersonGroups;
        }

        /// <summary> Initializes a new instance of LivenessSessions. </summary>
        public virtual LivenessSessions GetLivenessSessionsClient()
        {
            return Volatile.Read(ref _cachedLivenessSessions) ?? Interlocked.CompareExchange(ref _cachedLivenessSessions, new LivenessSessions(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedLivenessSessions;
        }

        /// <summary> Initializes a new instance of LivenessWithVerifySessions. </summary>
        public virtual LivenessWithVerifySessions GetLivenessWithVerifySessionsClient()
        {
            return Volatile.Read(ref _cachedLivenessWithVerifySessions) ?? Interlocked.CompareExchange(ref _cachedLivenessWithVerifySessions, new LivenessWithVerifySessions(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedLivenessWithVerifySessions;
        }

        internal HttpMessage CreateDetectFromUrlRequest(RequestContent content, bool? returnFaceId, bool? returnFaceLandmarks, string returnFaceAttributes, string recognitionModel, bool? returnRecognitionModel, string detectionModel, int? faceIdTimeToLive, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/detect", false);
            if (returnFaceId != null)
            {
                uri.AppendQuery("returnFaceId", returnFaceId.Value, true);
            }
            if (returnFaceLandmarks != null)
            {
                uri.AppendQuery("returnFaceLandmarks", returnFaceLandmarks.Value, true);
            }
            if (returnFaceAttributes != null)
            {
                uri.AppendQuery("returnFaceAttributes", returnFaceAttributes, true);
            }
            if (recognitionModel != null)
            {
                uri.AppendQuery("recognitionModel", recognitionModel, true);
            }
            if (returnRecognitionModel != null)
            {
                uri.AppendQuery("returnRecognitionModel", returnRecognitionModel.Value, true);
            }
            if (detectionModel != null)
            {
                uri.AppendQuery("detectionModel", detectionModel, true);
            }
            if (faceIdTimeToLive != null)
            {
                uri.AppendQuery("faceIdTimeToLive", faceIdTimeToLive.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("content-type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateDetectFromStreamRequest(RequestContent content, bool? returnFaceId, bool? returnFaceLandmarks, string returnFaceAttributes, string recognitionModel, bool? returnRecognitionModel, string detectionModel, int? faceIdTimeToLive, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/detect", false);
            if (returnFaceId != null)
            {
                uri.AppendQuery("returnFaceId", returnFaceId.Value, true);
            }
            if (returnFaceLandmarks != null)
            {
                uri.AppendQuery("returnFaceLandmarks", returnFaceLandmarks.Value, true);
            }
            if (returnFaceAttributes != null)
            {
                uri.AppendQuery("returnFaceAttributes", returnFaceAttributes, true);
            }
            if (recognitionModel != null)
            {
                uri.AppendQuery("recognitionModel", recognitionModel, true);
            }
            if (returnRecognitionModel != null)
            {
                uri.AppendQuery("returnRecognitionModel", returnRecognitionModel.Value, true);
            }
            if (detectionModel != null)
            {
                uri.AppendQuery("detectionModel", detectionModel, true);
            }
            if (faceIdTimeToLive != null)
            {
                uri.AppendQuery("faceIdTimeToLive", faceIdTimeToLive.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("content-type", "application/octet-stream");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateFindSimilarRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/findsimilars", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateVerifyRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/verify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/group", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        private static RequestContext DefaultRequestContext = new RequestContext();
        internal static RequestContext FromCancellationToken(CancellationToken cancellationToken = default)
        {
            if (!cancellationToken.CanBeCanceled)
            {
                return DefaultRequestContext;
            }

            return new RequestContext() { CancellationToken = cancellationToken };
        }

        private static ResponseClassifier _responseClassifier200;
        private static ResponseClassifier ResponseClassifier200 => _responseClassifier200 ??= new StatusCodeClassifier(stackalloc ushort[] { 200 });
    }
}
