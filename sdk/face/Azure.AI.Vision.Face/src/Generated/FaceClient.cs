// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using Azure.Core;
using Azure.Core.Pipeline;

namespace Azure.AI.Vision.Face
{
    // Data plane generated client.
    /// <summary> The Face service client. </summary>
    public partial class FaceClient
    {
        private const string AuthorizationHeader = "Ocp-Apim-Subscription-Key";
        private readonly AzureKeyCredential _keyCredential;
        private static readonly string[] AuthorizationScopes = new string[] { "https://cognitiveservices.azure.com/.default" };
        private readonly TokenCredential _tokenCredential;
        private readonly HttpPipeline _pipeline;
        private readonly Uri _endpoint;
        private readonly string _apiVersion;

        /// <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        internal ClientDiagnostics ClientDiagnostics { get; }

        /// <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        public virtual HttpPipeline Pipeline => _pipeline;

        /// <summary> Initializes a new instance of FaceClient for mocking. </summary>
        protected FaceClient()
        {
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://{resource-name}.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, AzureKeyCredential credential) : this(endpoint, credential, new AzureAIVisionFaceClientOptions())
        {
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://{resource-name}.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, TokenCredential credential) : this(endpoint, credential, new AzureAIVisionFaceClientOptions())
        {
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://{resource-name}.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, AzureKeyCredential credential, AzureAIVisionFaceClientOptions options)
        {
            Argument.AssertNotNull(endpoint, nameof(endpoint));
            Argument.AssertNotNull(credential, nameof(credential));
            options ??= new AzureAIVisionFaceClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _keyCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new AzureKeyCredentialPolicy(_keyCredential, AuthorizationHeader) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Initializes a new instance of FaceClient. </summary>
        /// <param name="endpoint">
        /// Supported Cognitive Services endpoints (protocol and hostname, for example:
        /// https://{resource-name}.cognitiveservices.azure.com).
        /// </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public FaceClient(Uri endpoint, TokenCredential credential, AzureAIVisionFaceClientOptions options)
        {
            Argument.AssertNotNull(endpoint, nameof(endpoint));
            Argument.AssertNotNull(credential, nameof(credential));
            options ??= new AzureAIVisionFaceClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _tokenCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new BearerTokenAuthenticationPolicy(_tokenCredential, AuthorizationScopes) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="url"> URL of input image. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="url"/> is null. </exception>
        /// <remarks>
        /// &gt; [!IMPORTANT]
        /// &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. We will also retire the Snapshot API, which allowed biometric data transfer from one Face subscription to another. Existing customers have until 30 June 2023 to use the emotion, gender, age, smile, facial hair, hair, and makeup attributes and the Snapshot API through Face API before they are retired.
        ///
        /// *
        ///   * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
        ///   * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
        ///   * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
        ///   * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
        ///   * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
        ///   * For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
        ///   * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
        ///     * 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.
        ///     * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.
        ///     * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces. Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
        ///   * Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
        ///     * 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.
        ///     * 'recognition_02': Recognition model released in 2019 March.
        ///     * 'recognition_03': Recognition model released in 2020 May.
        ///     * 'recognition_04': Recognition model released in 2021 February. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrlAsync(Uri,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceDetectionResult>>> DetectFromUrlAsync(Uri url, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, FaceRecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, FaceDetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(url, nameof(url));

            RequestContext context = FromCancellationToken(cancellationToken);
            DetectFromUrlRequest detectFromUrlRequest = new DetectFromUrlRequest(url);
            Response response = await DetectFromUrlAsync(detectFromUrlRequest.ToRequestContent(), returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context).ConfigureAwait(false);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="url"> URL of input image. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="url"/> is null. </exception>
        /// <remarks>
        /// &gt; [!IMPORTANT]
        /// &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. We will also retire the Snapshot API, which allowed biometric data transfer from one Face subscription to another. Existing customers have until 30 June 2023 to use the emotion, gender, age, smile, facial hair, hair, and makeup attributes and the Snapshot API through Face API before they are retired.
        ///
        /// *
        ///   * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
        ///   * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
        ///   * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
        ///   * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
        ///   * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
        ///   * For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
        ///   * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
        ///     * 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.
        ///     * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.
        ///     * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces. Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
        ///   * Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
        ///     * 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.
        ///     * 'recognition_02': Recognition model released in 2019 March.
        ///     * 'recognition_03': Recognition model released in 2020 May.
        ///     * 'recognition_04': Recognition model released in 2021 February. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrl(Uri,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceDetectionResult>> DetectFromUrl(Uri url, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, FaceRecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, FaceDetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(url, nameof(url));

            RequestContext context = FromCancellationToken(cancellationToken);
            DetectFromUrlRequest detectFromUrlRequest = new DetectFromUrlRequest(url);
            Response response = DetectFromUrl(detectFromUrlRequest.ToRequestContent(), returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectFromUrlAsync(Uri,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrlAsync(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual async Task<Response> DetectFromUrlAsync(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.DetectFromUrl");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectFromUrlRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectFromUrl(Uri,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectFromUrl(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual Response DetectFromUrl(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.DetectFromUrl");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectFromUrlRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="imageContent"> The input image binary. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContent"/> is null. </exception>
        /// <remarks>
        /// &gt; [!IMPORTANT]
        /// &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. We will also retire the Snapshot API, which allowed biometric data transfer from one Face subscription to another. Existing customers have until 30 June 2023 to use the emotion, gender, age, smile, facial hair, hair, and makeup attributes and the Snapshot API through Face API before they are retired.
        ///
        /// *
        ///   * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
        ///   * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
        ///   * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
        ///   * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
        ///   * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
        ///   * For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
        ///   * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
        ///     * 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.
        ///     * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.
        ///     * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces. Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
        ///   * Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
        ///     * 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.
        ///     * 'recognition_02': Recognition model released in 2019 March.
        ///     * 'recognition_03': Recognition model released in 2020 May.
        ///     * 'recognition_04': Recognition model released in 2021 February. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectAsync(BinaryData,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceDetectionResult>>> DetectAsync(BinaryData imageContent, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, FaceRecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, FaceDetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(imageContent, nameof(imageContent));

            RequestContext context = FromCancellationToken(cancellationToken);
            using RequestContent content = imageContent;
            Response response = await DetectAsync(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context).ConfigureAwait(false);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
        /// <param name="imageContent"> The input image binary. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="imageContent"/> is null. </exception>
        /// <remarks>
        /// &gt; [!IMPORTANT]
        /// &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/. We will also retire the Snapshot API, which allowed biometric data transfer from one Face subscription to another. Existing customers have until 30 June 2023 to use the emotion, gender, age, smile, facial hair, hair, and makeup attributes and the Snapshot API through Face API before they are retired.
        ///
        /// *
        ///   * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in Face - Identify, Face - Verify, and Face - Find Similar. The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
        ///   * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
        ///   * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
        ///   * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
        ///   * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
        ///   * For optimal results when querying Face - Identify, Face - Verify, and Face - Find Similar ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
        ///   * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
        ///     * 'detection_01': The default detection model for Face - Detect. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected.
        ///     * 'detection_02': Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. Face attributes and landmarks are disabled if you choose this detection model.
        ///     * 'detection_03': Detection model released in 2021 February with improved accuracy especially on small faces. Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
        ///   * Different 'recognitionModel' values are provided. If follow-up operations like Verify, Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
        ///     * 'recognition_01': The default recognition model for Face - Detect. All those faceIds created before 2019 March are bonded with this recognition model.
        ///     * 'recognition_02': Recognition model released in 2019 March.
        ///     * 'recognition_03': Recognition model released in 2020 May.
        ///     * 'recognition_04': Recognition model released in 2021 February. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Detect(BinaryData,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceDetectionResult>> Detect(BinaryData imageContent, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, FaceRecognitionModel? recognitionModel = null, bool? returnRecognitionModel = null, FaceDetectionModel? detectionModel = null, int? faceIdTimeToLive = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(imageContent, nameof(imageContent));

            RequestContext context = FromCancellationToken(cancellationToken);
            using RequestContent content = imageContent;
            Response response = Detect(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel?.ToString(), returnRecognitionModel, detectionModel?.ToString(), faceIdTimeToLive, context);
            IReadOnlyList<FaceDetectionResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceDetectionResult> array = new List<FaceDetectionResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceDetectionResult.DeserializeFaceDetectionResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="DetectAsync(BinaryData,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='DetectAsync(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual async Task<Response> DetectAsync(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Detect");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="Detect(BinaryData,bool?,bool?,string,FaceRecognitionModel?,bool?,FaceDetectionModel?,int?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
        /// <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
        /// <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Supported face attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Face attribute analysis has additional computational and time cost. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
        /// <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
        /// <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
        /// <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Detect(RequestContent,bool?,bool?,string,string,bool?,string,int?,RequestContext)']/*" />
        public virtual Response Detect(RequestContent content, bool? returnFaceId = null, bool? returnFaceLandmarks = null, string returnFaceAttributes = null, string recognitionModel = null, bool? returnRecognitionModel = null, string detectionModel = null, int? faceIdTimeToLive = null, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Detect");
            scope.Start();
            try
            {
                using HttpMessage message = CreateDetectRequest(content, returnFaceId, returnFaceLandmarks, returnFaceAttributes, recognitionModel, returnRecognitionModel, detectionModel, faceIdTimeToLive, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. </summary>
        /// <param name="faceId"> faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
        /// <param name="faceIds"> An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="faceIds"/> is null. </exception>
        /// <remarks>
        /// Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
        ///
        /// Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
        ///
        /// The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarAsync(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceFindSimilarResult>>> FindSimilarAsync(string faceId, IEnumerable<string> faceIds, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(faceIds, nameof(faceIds));

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarRequest findSimilarRequest = new FindSimilarRequest(faceId, faceIds.ToList())
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = await FindSimilarAsync(findSimilarRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceFindSimilarResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceFindSimilarResult> array = new List<FaceFindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceFindSimilarResult.DeserializeFaceFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. </summary>
        /// <param name="faceId"> faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
        /// <param name="faceIds"> An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="faceIds"/> is null. </exception>
        /// <remarks>
        /// Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
        ///
        /// Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
        ///
        /// The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilar(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceFindSimilarResult>> FindSimilar(string faceId, IEnumerable<string> faceIds, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(faceIds, nameof(faceIds));

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarRequest findSimilarRequest = new FindSimilarRequest(faceId, faceIds.ToList())
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = FindSimilar(findSimilarRequest.ToRequestContent(), context);
            IReadOnlyList<FaceFindSimilarResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceFindSimilarResult> array = new List<FaceFindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceFindSimilarResult.DeserializeFaceFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilarAsync(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> FindSimilarAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilar");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilar(string,IEnumerable{string},int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilar(RequestContent,RequestContext)']/*" />
        public virtual Response FindSimilar(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilar");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a face list. A 'faceListId' is created by Create Face List. </summary>
        /// <param name="faceId"> faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
        /// <param name="faceListId"> An existing user-specified unique candidate face list, created in FaceList - Create. Face list contains a set of persistedFaceIds which are persisted and will never expire. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="faceListId"/> is null. </exception>
        /// <remarks>
        /// Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
        ///
        /// Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
        ///
        /// The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromFaceListAsync(string,string,int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceFindSimilarResult>>> FindSimilarFromFaceListAsync(string faceId, string faceListId, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(faceListId, nameof(faceListId));

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarFromFaceListRequest findSimilarFromFaceListRequest = new FindSimilarFromFaceListRequest(faceId, faceListId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = await FindSimilarFromFaceListAsync(findSimilarFromFaceListRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceFindSimilarResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceFindSimilarResult> array = new List<FaceFindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceFindSimilarResult.DeserializeFaceFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a face list. A 'faceListId' is created by Create Face List. </summary>
        /// <param name="faceId"> faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
        /// <param name="faceListId"> An existing user-specified unique candidate face list, created in FaceList - Create. Face list contains a set of persistedFaceIds which are persisted and will never expire. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="faceListId"/> is null. </exception>
        /// <remarks>
        /// Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
        ///
        /// Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
        ///
        /// The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromFaceList(string,string,int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceFindSimilarResult>> FindSimilarFromFaceList(string faceId, string faceListId, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(faceListId, nameof(faceListId));

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarFromFaceListRequest findSimilarFromFaceListRequest = new FindSimilarFromFaceListRequest(faceId, faceListId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = FindSimilarFromFaceList(findSimilarFromFaceListRequest.ToRequestContent(), context);
            IReadOnlyList<FaceFindSimilarResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceFindSimilarResult> array = new List<FaceFindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceFindSimilarResult.DeserializeFaceFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a face list. A 'faceListId' is created by Create Face List.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilarFromFaceListAsync(string,string,int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromFaceListAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> FindSimilarFromFaceListAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilarFromFaceList");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarFromFaceListRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a face list. A 'faceListId' is created by Create Face List.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilarFromFaceList(string,string,int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromFaceList(RequestContent,RequestContext)']/*" />
        public virtual Response FindSimilarFromFaceList(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilarFromFaceList");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarFromFaceListRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a large face list. A 'largeFaceListId' is created by Create large Face List. </summary>
        /// <param name="faceId"> faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
        /// <param name="largeFaceListId"> An existing user-specified unique candidate large face list, created in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are persisted and will never expire. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="largeFaceListId"/> is null. </exception>
        /// <remarks>
        /// Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
        ///
        /// Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
        ///
        /// The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromLargeFaceListAsync(string,string,int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceFindSimilarResult>>> FindSimilarFromLargeFaceListAsync(string faceId, string largeFaceListId, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(largeFaceListId, nameof(largeFaceListId));

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarFromLargeFaceListRequest findSimilarFromLargeFaceListRequest = new FindSimilarFromLargeFaceListRequest(faceId, largeFaceListId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = await FindSimilarFromLargeFaceListAsync(findSimilarFromLargeFaceListRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceFindSimilarResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceFindSimilarResult> array = new List<FaceFindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceFindSimilarResult.DeserializeFaceFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> Given query face's faceId, to search the similar-looking faces from a large face list. A 'largeFaceListId' is created by Create large Face List. </summary>
        /// <param name="faceId"> faceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
        /// <param name="largeFaceListId"> An existing user-specified unique candidate large face list, created in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are persisted and will never expire. </param>
        /// <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000].It defaults to 20. </param>
        /// <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. It defaults to 'matchPerson'. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="largeFaceListId"/> is null. </exception>
        /// <remarks>
        /// Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
        ///
        /// Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
        ///
        /// The 'recognitionModel' associated with the query face's faceId should be the same as the 'recognitionModel' used by the target faceId array, face list or large face list.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromLargeFaceList(string,string,int?,FindSimilarMatchMode?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceFindSimilarResult>> FindSimilarFromLargeFaceList(string faceId, string largeFaceListId, int? maxNumOfCandidatesReturned = null, FindSimilarMatchMode? mode = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(largeFaceListId, nameof(largeFaceListId));

            RequestContext context = FromCancellationToken(cancellationToken);
            FindSimilarFromLargeFaceListRequest findSimilarFromLargeFaceListRequest = new FindSimilarFromLargeFaceListRequest(faceId, largeFaceListId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                Mode = mode
            };
            Response response = FindSimilarFromLargeFaceList(findSimilarFromLargeFaceListRequest.ToRequestContent(), context);
            IReadOnlyList<FaceFindSimilarResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceFindSimilarResult> array = new List<FaceFindSimilarResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceFindSimilarResult.DeserializeFaceFindSimilarResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a large face list. A 'largeFaceListId' is created by Create large Face List.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilarFromLargeFaceListAsync(string,string,int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromLargeFaceListAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> FindSimilarFromLargeFaceListAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilarFromLargeFaceList");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarFromLargeFaceListRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Given query face's faceId, to search the similar-looking faces from a large face list. A 'largeFaceListId' is created by Create large Face List.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="FindSimilarFromLargeFaceList(string,string,int?,FindSimilarMatchMode?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='FindSimilarFromLargeFaceList(RequestContent,RequestContext)']/*" />
        public virtual Response FindSimilarFromLargeFaceList(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.FindSimilarFromLargeFaceList");
            scope.Start();
            try
            {
                using HttpMessage message = CreateFindSimilarFromLargeFaceListRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a person group. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="personGroupId"> personGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="personGroupId"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonGroupAsync(IEnumerable{string},string,int?,float?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceIdentificationResult>>> IdentifyFromPersonGroupAsync(IEnumerable<string> faceIds, string personGroupId, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(personGroupId, nameof(personGroupId));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromPersonGroupRequest identifyFromPersonGroupRequest = new IdentifyFromPersonGroupRequest(faceIds.ToList(), personGroupId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = await IdentifyFromPersonGroupAsync(identifyFromPersonGroupRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a person group. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="personGroupId"> personGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="personGroupId"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonGroup(IEnumerable{string},string,int?,float?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceIdentificationResult>> IdentifyFromPersonGroup(IEnumerable<string> faceIds, string personGroupId, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(personGroupId, nameof(personGroupId));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromPersonGroupRequest identifyFromPersonGroupRequest = new IdentifyFromPersonGroupRequest(faceIds.ToList(), personGroupId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = IdentifyFromPersonGroup(identifyFromPersonGroupRequest.ToRequestContent(), context);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromPersonGroupAsync(IEnumerable{string},string,int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonGroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> IdentifyFromPersonGroupAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromPersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromPersonGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromPersonGroup(IEnumerable{string},string,int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonGroup(RequestContent,RequestContext)']/*" />
        public virtual Response IdentifyFromPersonGroup(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromPersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromPersonGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a large person group. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="largePersonGroupId"> largePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="largePersonGroupId"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromLargePersonGroupAsync(IEnumerable{string},string,int?,float?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceIdentificationResult>>> IdentifyFromLargePersonGroupAsync(IEnumerable<string> faceIds, string largePersonGroupId, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(largePersonGroupId, nameof(largePersonGroupId));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromLargePersonGroupRequest identifyFromLargePersonGroupRequest = new IdentifyFromLargePersonGroupRequest(faceIds.ToList(), largePersonGroupId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = await IdentifyFromLargePersonGroupAsync(identifyFromLargePersonGroupRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a large person group. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="largePersonGroupId"> largePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="largePersonGroupId"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromLargePersonGroup(IEnumerable{string},string,int?,float?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceIdentificationResult>> IdentifyFromLargePersonGroup(IEnumerable<string> faceIds, string largePersonGroupId, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(largePersonGroupId, nameof(largePersonGroupId));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromLargePersonGroupRequest identifyFromLargePersonGroupRequest = new IdentifyFromLargePersonGroupRequest(faceIds.ToList(), largePersonGroupId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = IdentifyFromLargePersonGroup(identifyFromLargePersonGroupRequest.ToRequestContent(), context);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a large person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromLargePersonGroupAsync(IEnumerable{string},string,int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromLargePersonGroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> IdentifyFromLargePersonGroupAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromLargePersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromLargePersonGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a large person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromLargePersonGroup(IEnumerable{string},string,int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromLargePersonGroup(RequestContent,RequestContext)']/*" />
        public virtual Response IdentifyFromLargePersonGroup(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromLargePersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromLargePersonGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a person directory personIds array. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="personIds"> Array of personIds created in PersonDirectory - PersonCreate. The valid number of personIds is between [1,30]. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="personIds"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonDirectoryAsync(IEnumerable{string},IEnumerable{string},int?,float?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceIdentificationResult>>> IdentifyFromPersonDirectoryAsync(IEnumerable<string> faceIds, IEnumerable<string> personIds, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(personIds, nameof(personIds));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromPersonDirectoryRequest identifyFromPersonDirectoryRequest = new IdentifyFromPersonDirectoryRequest(faceIds.ToList(), personIds.ToList())
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = await IdentifyFromPersonDirectoryAsync(identifyFromPersonDirectoryRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a person directory personIds array. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="personIds"> Array of personIds created in PersonDirectory - PersonCreate. The valid number of personIds is between [1,30]. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="personIds"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonDirectory(IEnumerable{string},IEnumerable{string},int?,float?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceIdentificationResult>> IdentifyFromPersonDirectory(IEnumerable<string> faceIds, IEnumerable<string> personIds, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(personIds, nameof(personIds));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromPersonDirectoryRequest identifyFromPersonDirectoryRequest = new IdentifyFromPersonDirectoryRequest(faceIds.ToList(), personIds.ToList())
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = IdentifyFromPersonDirectory(identifyFromPersonDirectoryRequest.ToRequestContent(), context);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a person directory personIds array.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromPersonDirectoryAsync(IEnumerable{string},IEnumerable{string},int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonDirectoryAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> IdentifyFromPersonDirectoryAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromPersonDirectory");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromPersonDirectoryRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a person directory personIds array.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromPersonDirectory(IEnumerable{string},IEnumerable{string},int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromPersonDirectory(RequestContent,RequestContext)']/*" />
        public virtual Response IdentifyFromPersonDirectory(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromPersonDirectory");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromPersonDirectoryRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a dynamic person group. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="dynamicPersonGroupId"> DynamicPersonGroupId of the target PersonDirectory DynamicPersonGroup to match against. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="dynamicPersonGroupId"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromDynamicPersonGroupAsync(IEnumerable{string},string,int?,float?,CancellationToken)']/*" />
        public virtual async Task<Response<IReadOnlyList<FaceIdentificationResult>>> IdentifyFromDynamicPersonGroupAsync(IEnumerable<string> faceIds, string dynamicPersonGroupId, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(dynamicPersonGroupId, nameof(dynamicPersonGroupId));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromDynamicPersonGroupRequest identifyFromDynamicPersonGroupRequest = new IdentifyFromDynamicPersonGroupRequest(faceIds.ToList(), dynamicPersonGroupId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = await IdentifyFromDynamicPersonGroupAsync(identifyFromDynamicPersonGroupRequest.ToRequestContent(), context).ConfigureAwait(false);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = await JsonDocument.ParseAsync(response.ContentStream, default, cancellationToken).ConfigureAwait(false);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary> 1-to-many identification to find the closest matches of the specific query person face from a dynamic person group. </summary>
        /// <param name="faceIds"> Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. </param>
        /// <param name="dynamicPersonGroupId"> DynamicPersonGroupId of the target PersonDirectory DynamicPersonGroup to match against. </param>
        /// <param name="maxNumOfCandidatesReturned"> The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 10). </param>
        /// <param name="confidenceThreshold"> Customized identification confidence threshold, in the range of [0, 1]. Advanced user can tweak this value to override default internal threshold for better precision on their scenario data. Note there is no guarantee of this threshold value working on other data and after algorithm updates. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> or <paramref name="dynamicPersonGroupId"/> is null. </exception>
        /// <remarks>
        /// For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId) or large person group (given by largePersonGroupId), and return candidate person(s) for that face ranked by similarity confidence. The person group/large person group should be trained to make it ready for identification. See more in PersonGroup - Train and LargePersonGroup - Train.
        ///
        /// &gt; [!NOTE]
        /// &gt; * The algorithm allows more than one face to be identified independently at the same request, but no more than 10 faces.
        /// &gt; * Each person in the person group/large person group could have more than one face, but no more than 248 faces.
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * Number of candidates returned is restricted by maxNumOfCandidatesReturned and confidenceThreshold. If no person is identified, the returned candidates will be an empty array.
        /// &gt; * Try Face - Find Similar when you need to find similar faces from a face list/large face list instead of a person group/large person group.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromDynamicPersonGroup(IEnumerable{string},string,int?,float?,CancellationToken)']/*" />
        public virtual Response<IReadOnlyList<FaceIdentificationResult>> IdentifyFromDynamicPersonGroup(IEnumerable<string> faceIds, string dynamicPersonGroupId, int? maxNumOfCandidatesReturned = null, float? confidenceThreshold = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));
            Argument.AssertNotNull(dynamicPersonGroupId, nameof(dynamicPersonGroupId));

            RequestContext context = FromCancellationToken(cancellationToken);
            IdentifyFromDynamicPersonGroupRequest identifyFromDynamicPersonGroupRequest = new IdentifyFromDynamicPersonGroupRequest(faceIds.ToList(), dynamicPersonGroupId)
            {
                MaxNumOfCandidatesReturned = maxNumOfCandidatesReturned,
                ConfidenceThreshold = confidenceThreshold
            };
            Response response = IdentifyFromDynamicPersonGroup(identifyFromDynamicPersonGroupRequest.ToRequestContent(), context);
            IReadOnlyList<FaceIdentificationResult> value = default;
            using var document = JsonDocument.Parse(response.ContentStream);
            List<FaceIdentificationResult> array = new List<FaceIdentificationResult>();
            foreach (var item in document.RootElement.EnumerateArray())
            {
                array.Add(FaceIdentificationResult.DeserializeFaceIdentificationResult(item));
            }
            value = array;
            return Response.FromValue(value, response);
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a dynamic person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromDynamicPersonGroupAsync(IEnumerable{string},string,int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromDynamicPersonGroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> IdentifyFromDynamicPersonGroupAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromDynamicPersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromDynamicPersonGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] 1-to-many identification to find the closest matches of the specific query person face from a dynamic person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="IdentifyFromDynamicPersonGroup(IEnumerable{string},string,int?,float?,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='IdentifyFromDynamicPersonGroup(RequestContent,RequestContext)']/*" />
        public virtual Response IdentifyFromDynamicPersonGroup(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.IdentifyFromDynamicPersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateIdentifyFromDynamicPersonGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Verify whether two faces belong to a same person. </summary>
        /// <param name="faceId1"> faceId of one face, comes from Face - Detect. </param>
        /// <param name="faceId2"> faceId of another face, comes from Face - Detect. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId1"/> or <paramref name="faceId2"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFaceToFaceAsync(string,string,CancellationToken)']/*" />
        public virtual async Task<Response<FaceVerificationResult>> VerifyFaceToFaceAsync(string faceId1, string faceId2, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId1, nameof(faceId1));
            Argument.AssertNotNull(faceId2, nameof(faceId2));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFaceToFaceRequest verifyFaceToFaceRequest = new VerifyFaceToFaceRequest(faceId1, faceId2);
            Response response = await VerifyFaceToFaceAsync(verifyFaceToFaceRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary> Verify whether two faces belong to a same person. </summary>
        /// <param name="faceId1"> faceId of one face, comes from Face - Detect. </param>
        /// <param name="faceId2"> faceId of another face, comes from Face - Detect. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId1"/> or <paramref name="faceId2"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFaceToFace(string,string,CancellationToken)']/*" />
        public virtual Response<FaceVerificationResult> VerifyFaceToFace(string faceId1, string faceId2, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId1, nameof(faceId1));
            Argument.AssertNotNull(faceId2, nameof(faceId2));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFaceToFaceRequest verifyFaceToFaceRequest = new VerifyFaceToFaceRequest(faceId1, faceId2);
            Response response = VerifyFaceToFace(verifyFaceToFaceRequest.ToRequestContent(), context);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Verify whether two faces belong to a same person.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFaceToFaceAsync(string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFaceToFaceAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> VerifyFaceToFaceAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFaceToFace");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFaceToFaceRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Verify whether two faces belong to a same person.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFaceToFace(string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFaceToFace(RequestContent,RequestContext)']/*" />
        public virtual Response VerifyFaceToFace(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFaceToFace");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFaceToFaceRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Verify whether one face belongs to a person in person group. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="personGroupId"> Using existing personGroupId and personId for fast loading a specified person. personGroupId is created in PersonGroup - Create. </param>
        /// <param name="personId"> Specify a certain person in person group. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/>, <paramref name="personGroupId"/> or <paramref name="personId"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonGroupAsync(string,string,string,CancellationToken)']/*" />
        public virtual async Task<Response<FaceVerificationResult>> VerifyFromPersonGroupAsync(string faceId, string personGroupId, string personId, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(personGroupId, nameof(personGroupId));
            Argument.AssertNotNull(personId, nameof(personId));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFromPersonGroupRequest verifyFromPersonGroupRequest = new VerifyFromPersonGroupRequest(faceId, personGroupId, personId);
            Response response = await VerifyFromPersonGroupAsync(verifyFromPersonGroupRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary> Verify whether one face belongs to a person in person group. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="personGroupId"> Using existing personGroupId and personId for fast loading a specified person. personGroupId is created in PersonGroup - Create. </param>
        /// <param name="personId"> Specify a certain person in person group. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/>, <paramref name="personGroupId"/> or <paramref name="personId"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonGroup(string,string,string,CancellationToken)']/*" />
        public virtual Response<FaceVerificationResult> VerifyFromPersonGroup(string faceId, string personGroupId, string personId, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(personGroupId, nameof(personGroupId));
            Argument.AssertNotNull(personId, nameof(personId));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFromPersonGroupRequest verifyFromPersonGroupRequest = new VerifyFromPersonGroupRequest(faceId, personGroupId, personId);
            Response response = VerifyFromPersonGroup(verifyFromPersonGroupRequest.ToRequestContent(), context);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Verify whether one face belongs to a person in person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFromPersonGroupAsync(string,string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonGroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> VerifyFromPersonGroupAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFromPersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFromPersonGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Verify whether one face belongs to a person in person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFromPersonGroup(string,string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonGroup(RequestContent,RequestContext)']/*" />
        public virtual Response VerifyFromPersonGroup(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFromPersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFromPersonGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Verify whether one face belongs to a person in large person group. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="largePersonGroupId"> Using existing largePersonGroupId and personId for fast loading a specified person. largePersonGroupId is created in LargePersonGroup - Create. </param>
        /// <param name="personId"> Specify a certain person in large person group. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/>, <paramref name="largePersonGroupId"/> or <paramref name="personId"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromLargePersonGroupAsync(string,string,string,CancellationToken)']/*" />
        public virtual async Task<Response<FaceVerificationResult>> VerifyFromLargePersonGroupAsync(string faceId, string largePersonGroupId, string personId, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(largePersonGroupId, nameof(largePersonGroupId));
            Argument.AssertNotNull(personId, nameof(personId));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFromLargePersonGroupRequest verifyFromLargePersonGroupRequest = new VerifyFromLargePersonGroupRequest(faceId, largePersonGroupId, personId);
            Response response = await VerifyFromLargePersonGroupAsync(verifyFromLargePersonGroupRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary> Verify whether one face belongs to a person in large person group. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="largePersonGroupId"> Using existing largePersonGroupId and personId for fast loading a specified person. largePersonGroupId is created in LargePersonGroup - Create. </param>
        /// <param name="personId"> Specify a certain person in large person group. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/>, <paramref name="largePersonGroupId"/> or <paramref name="personId"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromLargePersonGroup(string,string,string,CancellationToken)']/*" />
        public virtual Response<FaceVerificationResult> VerifyFromLargePersonGroup(string faceId, string largePersonGroupId, string personId, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(largePersonGroupId, nameof(largePersonGroupId));
            Argument.AssertNotNull(personId, nameof(personId));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFromLargePersonGroupRequest verifyFromLargePersonGroupRequest = new VerifyFromLargePersonGroupRequest(faceId, largePersonGroupId, personId);
            Response response = VerifyFromLargePersonGroup(verifyFromLargePersonGroupRequest.ToRequestContent(), context);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Verify whether one face belongs to a person in large person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFromLargePersonGroupAsync(string,string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromLargePersonGroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> VerifyFromLargePersonGroupAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFromLargePersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFromLargePersonGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Verify whether one face belongs to a person in large person group.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFromLargePersonGroup(string,string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromLargePersonGroup(RequestContent,RequestContext)']/*" />
        public virtual Response VerifyFromLargePersonGroup(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFromLargePersonGroup");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFromLargePersonGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Verify whether one face belongs to a person directory person. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="personId"> Specify a certain person in PersonDirectory Person. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="personId"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonDirectoryAsync(string,string,CancellationToken)']/*" />
        public virtual async Task<Response<FaceVerificationResult>> VerifyFromPersonDirectoryAsync(string faceId, string personId, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(personId, nameof(personId));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFromPersonDirectoryRequest verifyFromPersonDirectoryRequest = new VerifyFromPersonDirectoryRequest(faceId, personId);
            Response response = await VerifyFromPersonDirectoryAsync(verifyFromPersonDirectoryRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary> Verify whether one face belongs to a person directory person. </summary>
        /// <param name="faceId"> faceId of the face, comes from Face - Detect. </param>
        /// <param name="personId"> Specify a certain person in PersonDirectory Person. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceId"/> or <paramref name="personId"/> is null. </exception>
        /// <remarks>
        /// &gt; [!NOTE]
        /// &gt; * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        /// &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
        /// &gt; * The 'recognitionModel' associated with the query faces' faceIds should be the same as the 'recognitionModel' used by the target face, person group or large person group.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonDirectory(string,string,CancellationToken)']/*" />
        public virtual Response<FaceVerificationResult> VerifyFromPersonDirectory(string faceId, string personId, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceId, nameof(faceId));
            Argument.AssertNotNull(personId, nameof(personId));

            RequestContext context = FromCancellationToken(cancellationToken);
            VerifyFromPersonDirectoryRequest verifyFromPersonDirectoryRequest = new VerifyFromPersonDirectoryRequest(faceId, personId);
            Response response = VerifyFromPersonDirectory(verifyFromPersonDirectoryRequest.ToRequestContent(), context);
            return Response.FromValue(FaceVerificationResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Verify whether one face belongs to a person directory person.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFromPersonDirectoryAsync(string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonDirectoryAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> VerifyFromPersonDirectoryAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFromPersonDirectory");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFromPersonDirectoryRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Verify whether one face belongs to a person directory person.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="VerifyFromPersonDirectory(string,string,CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='VerifyFromPersonDirectory(RequestContent,RequestContext)']/*" />
        public virtual Response VerifyFromPersonDirectory(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.VerifyFromPersonDirectory");
            scope.Start();
            try
            {
                using HttpMessage message = CreateVerifyFromPersonDirectoryRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Divide candidate faces into groups based on face similarity. </summary>
        /// <param name="faceIds"> Array of candidate faceId created by Face - Detect. The maximum is 1000 faces. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> is null. </exception>
        /// <remarks>
        /// * The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result.
        /// * MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts.
        /// * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try Face - Verify when you only have 2 candidate faces.
        /// * The 'recognitionModel' associated with the query faces' faceIds should be the same.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='GroupAsync(IEnumerable{string},CancellationToken)']/*" />
        public virtual async Task<Response<FaceGroupingResult>> GroupAsync(IEnumerable<string> faceIds, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));

            RequestContext context = FromCancellationToken(cancellationToken);
            GroupRequest groupRequest = new GroupRequest(faceIds.ToList());
            Response response = await GroupAsync(groupRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(FaceGroupingResult.FromResponse(response), response);
        }

        /// <summary> Divide candidate faces into groups based on face similarity. </summary>
        /// <param name="faceIds"> Array of candidate faceId created by Face - Detect. The maximum is 1000 faces. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="faceIds"/> is null. </exception>
        /// <remarks>
        /// * The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result.
        /// * MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts.
        /// * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try Face - Verify when you only have 2 candidate faces.
        /// * The 'recognitionModel' associated with the query faces' faceIds should be the same.
        /// </remarks>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Group(IEnumerable{string},CancellationToken)']/*" />
        public virtual Response<FaceGroupingResult> Group(IEnumerable<string> faceIds, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(faceIds, nameof(faceIds));

            RequestContext context = FromCancellationToken(cancellationToken);
            GroupRequest groupRequest = new GroupRequest(faceIds.ToList());
            Response response = Group(groupRequest.ToRequestContent(), context);
            return Response.FromValue(FaceGroupingResult.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Divide candidate faces into groups based on face similarity.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="GroupAsync(IEnumerable{string},CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='GroupAsync(RequestContent,RequestContext)']/*" />
        public virtual async Task<Response> GroupAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Group");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGroupRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Divide candidate faces into groups based on face similarity.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="Group(IEnumerable{string},CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <include file="Docs/FaceClient.xml" path="doc/members/member[@name='Group(RequestContent,RequestContext)']/*" />
        public virtual Response Group(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("FaceClient.Group");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGroupRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        internal HttpMessage CreateDetectFromUrlRequest(RequestContent content, bool? returnFaceId, bool? returnFaceLandmarks, string returnFaceAttributes, string recognitionModel, bool? returnRecognitionModel, string detectionModel, int? faceIdTimeToLive, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/detect", false);
            if (returnFaceId != null)
            {
                uri.AppendQuery("returnFaceId", returnFaceId.Value, true);
            }
            if (returnFaceLandmarks != null)
            {
                uri.AppendQuery("returnFaceLandmarks", returnFaceLandmarks.Value, true);
            }
            if (returnFaceAttributes != null)
            {
                uri.AppendQuery("returnFaceAttributes", returnFaceAttributes, true);
            }
            if (recognitionModel != null)
            {
                uri.AppendQuery("recognitionModel", recognitionModel, true);
            }
            if (returnRecognitionModel != null)
            {
                uri.AppendQuery("returnRecognitionModel", returnRecognitionModel.Value, true);
            }
            if (detectionModel != null)
            {
                uri.AppendQuery("detectionModel", detectionModel, true);
            }
            if (faceIdTimeToLive != null)
            {
                uri.AppendQuery("faceIdTimeToLive", faceIdTimeToLive.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("content-type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateDetectRequest(RequestContent content, bool? returnFaceId, bool? returnFaceLandmarks, string returnFaceAttributes, string recognitionModel, bool? returnRecognitionModel, string detectionModel, int? faceIdTimeToLive, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/detect", false);
            if (returnFaceId != null)
            {
                uri.AppendQuery("returnFaceId", returnFaceId.Value, true);
            }
            if (returnFaceLandmarks != null)
            {
                uri.AppendQuery("returnFaceLandmarks", returnFaceLandmarks.Value, true);
            }
            if (returnFaceAttributes != null)
            {
                uri.AppendQuery("returnFaceAttributes", returnFaceAttributes, true);
            }
            if (recognitionModel != null)
            {
                uri.AppendQuery("recognitionModel", recognitionModel, true);
            }
            if (returnRecognitionModel != null)
            {
                uri.AppendQuery("returnRecognitionModel", returnRecognitionModel.Value, true);
            }
            if (detectionModel != null)
            {
                uri.AppendQuery("detectionModel", detectionModel, true);
            }
            if (faceIdTimeToLive != null)
            {
                uri.AppendQuery("faceIdTimeToLive", faceIdTimeToLive.Value, true);
            }
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("content-type", "application/octet-stream");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateFindSimilarRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/findsimilars", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateFindSimilarFromFaceListRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/findsimilars", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateFindSimilarFromLargeFaceListRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/findsimilars", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateIdentifyFromPersonGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/identify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateIdentifyFromLargePersonGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/identify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateIdentifyFromPersonDirectoryRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/identify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateIdentifyFromDynamicPersonGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/identify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateVerifyFaceToFaceRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/verify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateVerifyFromPersonGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/verify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateVerifyFromLargePersonGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/verify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateVerifyFromPersonDirectoryRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/verify", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateGroupRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/face/", false);
            uri.AppendPath(_apiVersion, true);
            uri.AppendPath("/group", false);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        private static RequestContext DefaultRequestContext = new RequestContext();
        internal static RequestContext FromCancellationToken(CancellationToken cancellationToken = default)
        {
            if (!cancellationToken.CanBeCanceled)
            {
                return DefaultRequestContext;
            }

            return new RequestContext() { CancellationToken = cancellationToken };
        }

        private static ResponseClassifier _responseClassifier200;
        private static ResponseClassifier ResponseClassifier200 => _responseClassifier200 ??= new StatusCodeClassifier(stackalloc ushort[] { 200 });
    }
}
