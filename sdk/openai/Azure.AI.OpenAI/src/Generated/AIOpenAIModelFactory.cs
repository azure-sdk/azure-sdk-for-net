// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;

namespace Azure.AI.OpenAI
{
    /// <summary> Model factory for models. </summary>
    public static partial class AIOpenAIModelFactory
    {
        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscriptionOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <param name="filename"> The optional filename or descriptive identifier to associate with with the audio data. </param>
        /// <param name="responseFormat"> The requested format of the transcription response data, which will influence the content and detail of the result. </param>
        /// <param name="language">
        /// The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code
        /// such as 'en' or 'fr'.
        /// Providing this known input language is optional but may improve the accuracy and/or latency of transcription.
        /// </param>
        /// <param name="prompt">
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </param>
        /// <param name="temperature">
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </param>
        /// <param name="timestampGranularities">
        /// The timestamp granularities to populate for this transcription.
        /// `response_format` must be set `verbose_json` to use timestamp granularities.
        /// Either or both of these options are supported: `word`, or `segment`.
        /// Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
        /// </param>
        /// <param name="deploymentName"> The model to use for this transcription request. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscriptionOptions"/> instance for mocking. </returns>
        public static AudioTranscriptionOptions AudioTranscriptionOptions(Stream audioData = null, string filename = null, AudioTranscriptionFormat? responseFormat = null, string language = null, string prompt = null, float? temperature = null, IEnumerable<AudioTranscriptionTimestampGranularity> timestampGranularities = null, string deploymentName = null)
        {
            timestampGranularities ??= new List<AudioTranscriptionTimestampGranularity>();

            return new AudioTranscriptionOptions(
                audioData,
                filename,
                responseFormat,
                language,
                prompt,
                temperature,
                timestampGranularities?.ToList(),
                deploymentName,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscriptionSegment"/>. </summary>
        /// <param name="id"> The 0-based index of this segment within a transcription. </param>
        /// <param name="start"> The time at which this segment started relative to the beginning of the transcribed audio. </param>
        /// <param name="end"> The time at which this segment ended relative to the beginning of the transcribed audio. </param>
        /// <param name="text"> The transcribed text that was part of this audio segment. </param>
        /// <param name="temperature"> The temperature score associated with this audio segment. </param>
        /// <param name="averageLogProbability"> The average log probability associated with this audio segment. </param>
        /// <param name="compressionRatio"> The compression ratio of this audio segment. </param>
        /// <param name="noSpeechProbability"> The probability of no speech detection within this audio segment. </param>
        /// <param name="tokens"> The token IDs matching the transcribed text in this audio segment. </param>
        /// <param name="seek">
        /// The seek position associated with the processing of this audio segment.
        /// Seek positions are expressed as hundredths of seconds.
        /// The model may process several segments from a single seek position, so while the seek position will never represent
        /// a later time than the segment's start, the segment's start may represent a significantly later time than the
        /// segment's associated seek position.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscriptionSegment"/> instance for mocking. </returns>
        public static AudioTranscriptionSegment AudioTranscriptionSegment(int id = default, TimeSpan start = default, TimeSpan end = default, string text = null, float temperature = default, float averageLogProbability = default, float compressionRatio = default, float noSpeechProbability = default, IEnumerable<int> tokens = null, int seek = default)
        {
            tokens ??= new List<int>();

            return new AudioTranscriptionSegment(
                id,
                start,
                end,
                text,
                temperature,
                averageLogProbability,
                compressionRatio,
                noSpeechProbability,
                tokens?.ToList(),
                seek,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscriptionWord"/>. </summary>
        /// <param name="word"> The textual content of the word. </param>
        /// <param name="start"> The start time of the word relative to the beginning of the audio, expressed in seconds. </param>
        /// <param name="end"> The end time of the word relative to the beginning of the audio, expressed in seconds. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscriptionWord"/> instance for mocking. </returns>
        public static AudioTranscriptionWord AudioTranscriptionWord(string word = null, TimeSpan start = default, TimeSpan end = default)
        {
            return new AudioTranscriptionWord(word, start, end, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranslationOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to translate. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <param name="filename"> The optional filename or descriptive identifier to associate with with the audio data. </param>
        /// <param name="responseFormat"> The requested format of the translation response data, which will influence the content and detail of the result. </param>
        /// <param name="prompt">
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </param>
        /// <param name="temperature">
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </param>
        /// <param name="deploymentName"> The model to use for this translation request. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranslationOptions"/> instance for mocking. </returns>
        public static AudioTranslationOptions AudioTranslationOptions(Stream audioData = null, string filename = null, AudioTranslationFormat? responseFormat = null, string prompt = null, float? temperature = null, string deploymentName = null)
        {
            return new AudioTranslationOptions(
                audioData,
                filename,
                responseFormat,
                prompt,
                temperature,
                deploymentName,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranslationSegment"/>. </summary>
        /// <param name="id"> The 0-based index of this segment within a translation. </param>
        /// <param name="start"> The time at which this segment started relative to the beginning of the translated audio. </param>
        /// <param name="end"> The time at which this segment ended relative to the beginning of the translated audio. </param>
        /// <param name="text"> The translated text that was part of this audio segment. </param>
        /// <param name="temperature"> The temperature score associated with this audio segment. </param>
        /// <param name="averageLogProbability"> The average log probability associated with this audio segment. </param>
        /// <param name="compressionRatio"> The compression ratio of this audio segment. </param>
        /// <param name="noSpeechProbability"> The probability of no speech detection within this audio segment. </param>
        /// <param name="tokens"> The token IDs matching the translated text in this audio segment. </param>
        /// <param name="seek">
        /// The seek position associated with the processing of this audio segment.
        /// Seek positions are expressed as hundredths of seconds.
        /// The model may process several segments from a single seek position, so while the seek position will never represent
        /// a later time than the segment's start, the segment's start may represent a significantly later time than the
        /// segment's associated seek position.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AudioTranslationSegment"/> instance for mocking. </returns>
        public static AudioTranslationSegment AudioTranslationSegment(int id = default, TimeSpan start = default, TimeSpan end = default, string text = null, float temperature = default, float averageLogProbability = default, float compressionRatio = default, float noSpeechProbability = default, IEnumerable<int> tokens = null, int seek = default)
        {
            tokens ??= new List<int>();

            return new AudioTranslationSegment(
                id,
                start,
                end,
                text,
                temperature,
                averageLogProbability,
                compressionRatio,
                noSpeechProbability,
                tokens?.ToList(),
                seek,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.Completions"/>. </summary>
        /// <param name="id"> A unique identifier associated with this completions response. </param>
        /// <param name="created">
        /// The first timestamp associated with generation activity for this completions response,
        /// represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
        /// </param>
        /// <param name="promptFilterResults">
        /// Content filtering results for zero or more prompts in the request. In a streaming request,
        /// results for different prompts may arrive at different times or in different orders.
        /// </param>
        /// <param name="choices">
        /// The collection of completions choices associated with this completions response.
        /// Generally, `n` choices are generated per provided prompt with a default value of 1.
        /// Token limits and other settings may limit the number of choices generated.
        /// </param>
        /// <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
        /// <param name="systemFingerprint">
        /// This fingerprint represents the backend configuration that the model runs with.
        ///
        /// Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        /// </param>
        /// <returns> A new <see cref="OpenAI.Completions"/> instance for mocking. </returns>
        public static Completions Completions(string id = null, DateTimeOffset created = default, IEnumerable<ContentFilterResultsForPrompt> promptFilterResults = null, IEnumerable<Choice> choices = null, CompletionsUsage usage = null, string systemFingerprint = null)
        {
            promptFilterResults ??= new List<ContentFilterResultsForPrompt>();
            choices ??= new List<Choice>();

            return new Completions(
                id,
                created,
                promptFilterResults?.ToList(),
                choices?.ToList(),
                usage,
                systemFingerprint,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResultsForPrompt"/>. </summary>
        /// <param name="promptIndex"> The index of this prompt in the set of prompt results. </param>
        /// <param name="contentFilterResults"> Content filtering results for this prompt. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResultsForPrompt"/> instance for mocking. </returns>
        public static ContentFilterResultsForPrompt ContentFilterResultsForPrompt(int promptIndex = default, ContentFilterResultDetailsForPrompt contentFilterResults = null)
        {
            return new ContentFilterResultsForPrompt(promptIndex, contentFilterResults, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResultDetailsForPrompt"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <param name="profanity"> Describes whether profanity was detected. </param>
        /// <param name="customBlocklists"> Describes detection results against configured custom blocklists. </param>
        /// <param name="error">
        /// Describes an error returned if the content filtering system is
        /// down or otherwise unable to complete the operation in time.
        /// </param>
        /// <param name="jailbreak"> Whether a jailbreak attempt was detected in the prompt. </param>
        /// <param name="indirectAttack"> Whether an indirect attack was detected in the prompt. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResultDetailsForPrompt"/> instance for mocking. </returns>
        public static ContentFilterResultDetailsForPrompt ContentFilterResultDetailsForPrompt(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null, ContentFilterDetectionResult profanity = null, ContentFilterDetailedResults customBlocklists = null, ResponseError error = null, ContentFilterDetectionResult jailbreak = null, ContentFilterDetectionResult indirectAttack = null)
        {
            return new ContentFilterResultDetailsForPrompt(
                sexual,
                violence,
                hate,
                selfHarm,
                profanity,
                customBlocklists,
                error,
                jailbreak,
                indirectAttack,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="severity"> Ratings for the intensity and risk level of filtered content. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResult"/> instance for mocking. </returns>
        public static ContentFilterResult ContentFilterResult(bool filtered = default, ContentFilterSeverity severity = default)
        {
            return new ContentFilterResult(filtered, severity, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterDetectionResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="detected"> A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterDetectionResult"/> instance for mocking. </returns>
        public static ContentFilterDetectionResult ContentFilterDetectionResult(bool filtered = default, bool detected = default)
        {
            return new ContentFilterDetectionResult(filtered, detected, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterDetailedResults"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="details"> The collection of detailed blocklist result information. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterDetailedResults"/> instance for mocking. </returns>
        public static ContentFilterDetailedResults ContentFilterDetailedResults(bool filtered = default, IEnumerable<ContentFilterBlocklistIdResult> details = null)
        {
            details ??= new List<ContentFilterBlocklistIdResult>();

            return new ContentFilterDetailedResults(filtered, details?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterBlocklistIdResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="id"> The ID of the custom blocklist evaluated. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterBlocklistIdResult"/> instance for mocking. </returns>
        public static ContentFilterBlocklistIdResult ContentFilterBlocklistIdResult(bool filtered = default, string id = null)
        {
            return new ContentFilterBlocklistIdResult(filtered, id, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.Choice"/>. </summary>
        /// <param name="text"> The generated text for a given completions prompt. </param>
        /// <param name="index"> The ordered index associated with this completions choice. </param>
        /// <param name="contentFilterResults">
        /// Information about the content filtering category (hate, sexual, violence, self_harm), if it
        /// has been detected, as well as the severity level (very_low, low, medium, high-scale that
        /// determines the intensity and risk level of harmful content) and if it has been filtered or not.
        /// </param>
        /// <param name="logProbabilityModel"> The log probabilities model for tokens associated with this completions choice. </param>
        /// <param name="finishReason"> Reason for finishing. </param>
        /// <returns> A new <see cref="OpenAI.Choice"/> instance for mocking. </returns>
        public static Choice Choice(string text = null, int index = default, ContentFilterResultsForChoice contentFilterResults = null, CompletionsLogProbabilityModel logProbabilityModel = null, CompletionsFinishReason? finishReason = null)
        {
            return new Choice(
                text,
                index,
                contentFilterResults,
                logProbabilityModel,
                finishReason,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResultsForChoice"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <param name="profanity"> Describes whether profanity was detected. </param>
        /// <param name="customBlocklists"> Describes detection results against configured custom blocklists. </param>
        /// <param name="error">
        /// Describes an error returned if the content filtering system is
        /// down or otherwise unable to complete the operation in time.
        /// </param>
        /// <param name="protectedMaterialText"> Information about detection of protected text material. </param>
        /// <param name="protectedMaterialCode"> Information about detection of protected code material. </param>
        /// <param name="ungroundedMaterial"> Information about detection of ungrounded material. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResultsForChoice"/> instance for mocking. </returns>
        public static ContentFilterResultsForChoice ContentFilterResultsForChoice(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null, ContentFilterDetectionResult profanity = null, ContentFilterDetailedResults customBlocklists = null, ResponseError error = null, ContentFilterDetectionResult protectedMaterialText = null, ContentFilterCitedDetectionResult protectedMaterialCode = null, ContentFilterCompletionTextSpanResult ungroundedMaterial = null)
        {
            return new ContentFilterResultsForChoice(
                sexual,
                violence,
                hate,
                selfHarm,
                profanity,
                customBlocklists,
                error,
                protectedMaterialText,
                protectedMaterialCode,
                ungroundedMaterial,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterCitedDetectionResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="detected"> A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. </param>
        /// <param name="url"> The internet location associated with the detection. </param>
        /// <param name="license"> The license description associated with the detection. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterCitedDetectionResult"/> instance for mocking. </returns>
        public static ContentFilterCitedDetectionResult ContentFilterCitedDetectionResult(bool filtered = default, bool detected = default, Uri url = null, string license = null)
        {
            return new ContentFilterCitedDetectionResult(filtered, detected, url, license, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterCompletionTextSpanResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="detected"> A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. </param>
        /// <param name="details"> The collection of completion text spans. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterCompletionTextSpanResult"/> instance for mocking. </returns>
        public static ContentFilterCompletionTextSpanResult ContentFilterCompletionTextSpanResult(bool filtered = default, bool detected = default, IEnumerable<ContentFilterCompletionTextSpan> details = null)
        {
            details ??= new List<ContentFilterCompletionTextSpan>();

            return new ContentFilterCompletionTextSpanResult(filtered, detected, details?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterCompletionTextSpan"/>. </summary>
        /// <param name="completionStartOffset"> Offset of the UTF32 code point which begins the span. </param>
        /// <param name="completionEndOffset">
        /// Offset of the first UTF32 code point which is excluded from the span.
        /// This field is always equal to completion_start_offset for empty spans.
        /// This field is always larger than completion_start_offset for non-empty spans.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterCompletionTextSpan"/> instance for mocking. </returns>
        public static ContentFilterCompletionTextSpan ContentFilterCompletionTextSpan(int completionStartOffset = default, int completionEndOffset = default)
        {
            return new ContentFilterCompletionTextSpan(completionStartOffset, completionEndOffset, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.CompletionsLogProbabilityModel"/>. </summary>
        /// <param name="tokens"> The textual forms of tokens evaluated in this probability model. </param>
        /// <param name="tokenLogProbabilities"> A collection of log probability values for the tokens in this completions data. </param>
        /// <param name="topLogProbabilities"> A mapping of tokens to maximum log probability values in this completions data. </param>
        /// <param name="textOffsets"> The text offsets associated with tokens in this completions data. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsLogProbabilityModel"/> instance for mocking. </returns>
        public static CompletionsLogProbabilityModel CompletionsLogProbabilityModel(IEnumerable<string> tokens = null, IEnumerable<float?> tokenLogProbabilities = null, IEnumerable<IDictionary<string, float?>> topLogProbabilities = null, IEnumerable<int> textOffsets = null)
        {
            tokens ??= new List<string>();
            tokenLogProbabilities ??= new List<float?>();
            topLogProbabilities ??= new List<IDictionary<string, float?>>();
            textOffsets ??= new List<int>();

            return new CompletionsLogProbabilityModel(tokens?.ToList(), tokenLogProbabilities?.ToList(), topLogProbabilities?.ToList(), textOffsets?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.CompletionsUsage"/>. </summary>
        /// <param name="completionTokens"> The number of tokens generated across all completions emissions. </param>
        /// <param name="promptTokens"> The number of tokens in the provided prompts for the completions request. </param>
        /// <param name="totalTokens"> The total number of tokens processed for the completions request and response. </param>
        /// <param name="promptTokensDetails"> Details of the prompt tokens. </param>
        /// <param name="completionTokensDetails"> Breakdown of tokens used in a completion. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsUsage"/> instance for mocking. </returns>
        public static CompletionsUsage CompletionsUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default, CompletionsUsagePromptTokensDetails promptTokensDetails = null, CompletionsUsageCompletionTokensDetails completionTokensDetails = null)
        {
            return new CompletionsUsage(
                completionTokens,
                promptTokens,
                totalTokens,
                promptTokensDetails,
                completionTokensDetails,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.CompletionsUsagePromptTokensDetails"/>. </summary>
        /// <param name="audioTokens"> Audio input tokens present in the prompt. </param>
        /// <param name="cachedTokens"> Cached tokens present in the prompt. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsUsagePromptTokensDetails"/> instance for mocking. </returns>
        public static CompletionsUsagePromptTokensDetails CompletionsUsagePromptTokensDetails(int? audioTokens = null, int? cachedTokens = null)
        {
            return new CompletionsUsagePromptTokensDetails(audioTokens, cachedTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.CompletionsUsageCompletionTokensDetails"/>. </summary>
        /// <param name="acceptedPredictionTokens">
        /// When using Predicted Outputs, the number of tokens in the
        /// prediction that appeared in the completion.
        /// </param>
        /// <param name="audioTokens"> Audio input tokens generated by the model. </param>
        /// <param name="reasoningTokens"> Tokens generated by the model for reasoning. </param>
        /// <param name="rejectedPredictionTokens">
        /// When using Predicted Outputs, the number of tokens in the
        /// prediction that did not appear in the completion. However, like
        /// reasoning tokens, these tokens are still counted in the total
        /// completion tokens for purposes of billing, output, and context
        /// window limits.
        /// </param>
        /// <returns> A new <see cref="OpenAI.CompletionsUsageCompletionTokensDetails"/> instance for mocking. </returns>
        public static CompletionsUsageCompletionTokensDetails CompletionsUsageCompletionTokensDetails(int? acceptedPredictionTokens = null, int? audioTokens = null, int? reasoningTokens = null, int? rejectedPredictionTokens = null)
        {
            return new CompletionsUsageCompletionTokensDetails(acceptedPredictionTokens, audioTokens, reasoningTokens, rejectedPredictionTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestSystemMessage"/>. </summary>
        /// <param name="content"> The contents of the system message. </param>
        /// <param name="name"> An optional name for the participant. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestSystemMessage"/> instance for mocking. </returns>
        public static ChatRequestSystemMessage ChatRequestSystemMessage(BinaryData content = null, string name = null)
        {
            return new ChatRequestSystemMessage(ChatRole.System, serializedAdditionalRawData: null, content, name);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatMessageTextContentItem"/>. </summary>
        /// <param name="text"> The content of the message. </param>
        /// <returns> A new <see cref="OpenAI.ChatMessageTextContentItem"/> instance for mocking. </returns>
        public static ChatMessageTextContentItem ChatMessageTextContentItem(string text = null)
        {
            return new ChatMessageTextContentItem("text", serializedAdditionalRawData: null, text);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatMessageRefusalContentItem"/>. </summary>
        /// <param name="refusal"> The refusal message. </param>
        /// <returns> A new <see cref="OpenAI.ChatMessageRefusalContentItem"/> instance for mocking. </returns>
        public static ChatMessageRefusalContentItem ChatMessageRefusalContentItem(string refusal = null)
        {
            return new ChatMessageRefusalContentItem("refusal", serializedAdditionalRawData: null, refusal);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatMessageImageContentItem"/>. </summary>
        /// <param name="imageUrl"> An internet location, which must be accessible to the model,from which the image may be retrieved. </param>
        /// <returns> A new <see cref="OpenAI.ChatMessageImageContentItem"/> instance for mocking. </returns>
        public static ChatMessageImageContentItem ChatMessageImageContentItem(ChatMessageImageUrl imageUrl = null)
        {
            return new ChatMessageImageContentItem("image_url", serializedAdditionalRawData: null, imageUrl);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatMessageImageUrl"/>. </summary>
        /// <param name="url"> The URL of the image. </param>
        /// <param name="detail">
        /// The evaluation quality setting to use, which controls relative prioritization of speed, token consumption, and
        /// accuracy.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ChatMessageImageUrl"/> instance for mocking. </returns>
        public static ChatMessageImageUrl ChatMessageImageUrl(Uri url = null, ChatMessageImageDetailLevel? detail = null)
        {
            return new ChatMessageImageUrl(url, detail, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatMessageAudioContentItem"/>. </summary>
        /// <param name="inputAudio"> The audio data. </param>
        /// <returns> A new <see cref="OpenAI.ChatMessageAudioContentItem"/> instance for mocking. </returns>
        public static ChatMessageAudioContentItem ChatMessageAudioContentItem(InputAudioContent inputAudio = null)
        {
            return new ChatMessageAudioContentItem("input_audio", serializedAdditionalRawData: null, inputAudio);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestDeveloperMessage"/>. </summary>
        /// <param name="content"> An array of content parts with a defined type. For developer messages, only type `text` is supported. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestDeveloperMessage"/> instance for mocking. </returns>
        public static ChatRequestDeveloperMessage ChatRequestDeveloperMessage(BinaryData content = null, string name = null)
        {
            return new ChatRequestDeveloperMessage(ChatRole.Developer, serializedAdditionalRawData: null, content, name);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestUserMessage"/>. </summary>
        /// <param name="content"> The contents of the user message, with available input types varying by selected model. </param>
        /// <param name="name"> An optional name for the participant. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestUserMessage"/> instance for mocking. </returns>
        public static ChatRequestUserMessage ChatRequestUserMessage(BinaryData content = null, string name = null)
        {
            return new ChatRequestUserMessage(ChatRole.User, serializedAdditionalRawData: null, content, name);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestAssistantMessage"/>. </summary>
        /// <param name="content"> The content of the message. </param>
        /// <param name="name"> An optional name for the participant. </param>
        /// <param name="toolCalls">
        /// The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// Please note <see cref="ChatCompletionsToolCall"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ChatCompletionsFunctionToolCall"/>.
        /// </param>
        /// <param name="functionCall">
        /// The function call that must be resolved and have its output appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// </param>
        /// <param name="refusal"> The refusal message by the assistant. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestAssistantMessage"/> instance for mocking. </returns>
        public static ChatRequestAssistantMessage ChatRequestAssistantMessage(BinaryData content = null, string name = null, IEnumerable<ChatCompletionsToolCall> toolCalls = null, FunctionCall functionCall = null, string refusal = null)
        {
            toolCalls ??= new List<ChatCompletionsToolCall>();

            return new ChatRequestAssistantMessage(
                ChatRole.Assistant,
                serializedAdditionalRawData: null,
                content,
                name,
                toolCalls?.ToList(),
                functionCall,
                refusal);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestToolMessage"/>. </summary>
        /// <param name="content"> The content of the message. </param>
        /// <param name="toolCallId"> The ID of the tool call resolved by the provided content. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestToolMessage"/> instance for mocking. </returns>
        public static ChatRequestToolMessage ChatRequestToolMessage(BinaryData content = null, string toolCallId = null)
        {
            return new ChatRequestToolMessage(ChatRole.Tool, serializedAdditionalRawData: null, content, toolCallId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestFunctionMessage"/>. </summary>
        /// <param name="name"> The name of the function that was called to produce output. </param>
        /// <param name="content"> The output of the function as requested by the function call. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestFunctionMessage"/> instance for mocking. </returns>
        public static ChatRequestFunctionMessage ChatRequestFunctionMessage(string name = null, string content = null)
        {
            return new ChatRequestFunctionMessage(ChatRole.Function, serializedAdditionalRawData: null, name, content);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.FunctionDefinition"/>. </summary>
        /// <param name="name"> The name of the function to be called. </param>
        /// <param name="description">
        /// A description of what the function does. The model will use this description when selecting the function and
        /// interpreting its parameters.
        /// </param>
        /// <param name="parameters"> The parameters the function accepts, described as a JSON Schema object. </param>
        /// <returns> A new <see cref="OpenAI.FunctionDefinition"/> instance for mocking. </returns>
        public static FunctionDefinition FunctionDefinition(string name = null, string description = null, BinaryData parameters = null)
        {
            return new FunctionDefinition(name, description, parameters, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureSearchChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Azure Search. </param>
        /// <returns> A new <see cref="OpenAI.AzureSearchChatExtensionConfiguration"/> instance for mocking. </returns>
        public static AzureSearchChatExtensionConfiguration AzureSearchChatExtensionConfiguration(AzureSearchChatExtensionParameters parameters = null)
        {
            return new AzureSearchChatExtensionConfiguration(AzureChatExtensionType.AzureSearch, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureSearchChatExtensionParameters"/>. </summary>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="maxSearchQueries">
        /// The max number of rewritten queries should be send to search provider for one user message. If not specified,
        /// the system will decide the number of queries to send.
        /// </param>
        /// <param name="allowPartialResult">
        /// If specified as true, the system will allow partial search results to be used and the request fails if all the queries fail.
        /// If not specified, or specified as false, the request will fail if any search query fails.
        /// </param>
        /// <param name="includeContexts"> The included properties of the output context. If not specified, the default value is `citations` and `intent`. </param>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUsernameAndPasswordAuthenticationOptions"/>.
        /// </param>
        /// <param name="searchEndpoint"> The absolute endpoint path for the Azure Cognitive Search resource to use. </param>
        /// <param name="indexName"> The name of the index to use as available in the referenced Azure Cognitive Search resource. </param>
        /// <param name="fieldMappingOptions"> Customized field mapping behavior to use when interacting with the search index. </param>
        /// <param name="queryType"> The query type to use with Azure Cognitive Search. </param>
        /// <param name="semanticConfiguration"> The additional semantic configuration for the query. </param>
        /// <param name="filter"> Search filter. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/>, <see cref="OnYourDataIntegratedVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AzureSearchChatExtensionParameters"/> instance for mocking. </returns>
        public static AzureSearchChatExtensionParameters AzureSearchChatExtensionParameters(int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, int? maxSearchQueries = null, bool? allowPartialResult = null, IEnumerable<OnYourDataContextProperty> includeContexts = null, OnYourDataAuthenticationOptions authentication = null, Uri searchEndpoint = null, string indexName = null, AzureSearchIndexFieldMappingOptions fieldMappingOptions = null, AzureSearchQueryType? queryType = null, string semanticConfiguration = null, string filter = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            includeContexts ??= new List<OnYourDataContextProperty>();

            return new AzureSearchChatExtensionParameters(
                documentCount,
                shouldRestrictResultScope,
                strictness,
                maxSearchQueries,
                allowPartialResult,
                includeContexts?.ToList(),
                authentication,
                searchEndpoint,
                indexName,
                fieldMappingOptions,
                queryType,
                semanticConfiguration,
                filter,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>. </summary>
        /// <param name="key"> The API key to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataApiKeyAuthenticationOptions OnYourDataApiKeyAuthenticationOptions(string key = null)
        {
            return new OnYourDataApiKeyAuthenticationOptions(OnYourDataAuthenticationType.ApiKey, serializedAdditionalRawData: null, key);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>. </summary>
        /// <param name="connectionString"> The connection string to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataConnectionStringAuthenticationOptions OnYourDataConnectionStringAuthenticationOptions(string connectionString = null)
        {
            return new OnYourDataConnectionStringAuthenticationOptions(OnYourDataAuthenticationType.ConnectionString, serializedAdditionalRawData: null, connectionString);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>. </summary>
        /// <param name="key"> The key to use for authentication. </param>
        /// <param name="keyId"> The key ID to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataKeyAndKeyIdAuthenticationOptions OnYourDataKeyAndKeyIdAuthenticationOptions(string key = null, string keyId = null)
        {
            return new OnYourDataKeyAndKeyIdAuthenticationOptions(OnYourDataAuthenticationType.KeyAndKeyId, serializedAdditionalRawData: null, key, keyId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>. </summary>
        /// <param name="encodedApiKey"> The encoded API key to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataEncodedApiKeyAuthenticationOptions OnYourDataEncodedApiKeyAuthenticationOptions(string encodedApiKey = null)
        {
            return new OnYourDataEncodedApiKeyAuthenticationOptions(OnYourDataAuthenticationType.EncodedApiKey, serializedAdditionalRawData: null, encodedApiKey);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataUsernameAndPasswordAuthenticationOptions"/>. </summary>
        /// <param name="username"> The username. </param>
        /// <param name="password"> The password. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataUsernameAndPasswordAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataUsernameAndPasswordAuthenticationOptions OnYourDataUsernameAndPasswordAuthenticationOptions(string username = null, string password = null)
        {
            return new OnYourDataUsernameAndPasswordAuthenticationOptions(OnYourDataAuthenticationType.UsernameAndPassword, serializedAdditionalRawData: null, username, password);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>. </summary>
        /// <param name="accessToken"> The access token to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataAccessTokenAuthenticationOptions OnYourDataAccessTokenAuthenticationOptions(string accessToken = null)
        {
            return new OnYourDataAccessTokenAuthenticationOptions(OnYourDataAuthenticationType.AccessToken, serializedAdditionalRawData: null, accessToken);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>. </summary>
        /// <param name="managedIdentityResourceId"> The resource ID of the user-assigned managed identity to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataUserAssignedManagedIdentityAuthenticationOptions OnYourDataUserAssignedManagedIdentityAuthenticationOptions(string managedIdentityResourceId = null)
        {
            return new OnYourDataUserAssignedManagedIdentityAuthenticationOptions(OnYourDataAuthenticationType.UserAssignedManagedIdentity, serializedAdditionalRawData: null, managedIdentityResourceId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/>. </summary>
        /// <param name="endpoint"> Specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings. The api-version query parameter is not allowed. </param>
        /// <param name="authentication">
        /// Specifies the authentication options to use when retrieving embeddings from the specified endpoint.
        /// Please note <see cref="OnYourDataVectorSearchAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataVectorSearchAccessTokenAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataVectorSearchApiKeyAuthenticationOptions"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/> instance for mocking. </returns>
        public static OnYourDataEndpointVectorizationSource OnYourDataEndpointVectorizationSource(Uri endpoint = null, OnYourDataVectorSearchAuthenticationOptions authentication = null)
        {
            return new OnYourDataEndpointVectorizationSource(OnYourDataVectorizationSourceType.Endpoint, serializedAdditionalRawData: null, endpoint, authentication);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataVectorSearchApiKeyAuthenticationOptions"/>. </summary>
        /// <param name="key"> The API key to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataVectorSearchApiKeyAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataVectorSearchApiKeyAuthenticationOptions OnYourDataVectorSearchApiKeyAuthenticationOptions(string key = null)
        {
            return new OnYourDataVectorSearchApiKeyAuthenticationOptions(OnYourDataVectorSearchAuthenticationType.ApiKey, serializedAdditionalRawData: null, key);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataVectorSearchAccessTokenAuthenticationOptions"/>. </summary>
        /// <param name="accessToken"> The access token to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataVectorSearchAccessTokenAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataVectorSearchAccessTokenAuthenticationOptions OnYourDataVectorSearchAccessTokenAuthenticationOptions(string accessToken = null)
        {
            return new OnYourDataVectorSearchAccessTokenAuthenticationOptions(OnYourDataVectorSearchAuthenticationType.AccessToken, serializedAdditionalRawData: null, accessToken);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>. </summary>
        /// <param name="deploymentName"> The embedding model deployment name within the same Azure OpenAI resource. This enables you to use vector search without Azure OpenAI api-key and without Azure OpenAI public network access. </param>
        /// <param name="dimensions"> The number of dimensions the embeddings should have. Only supported in `text-embedding-3` and later models. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/> instance for mocking. </returns>
        public static OnYourDataDeploymentNameVectorizationSource OnYourDataDeploymentNameVectorizationSource(string deploymentName = null, int? dimensions = null)
        {
            return new OnYourDataDeploymentNameVectorizationSource(OnYourDataVectorizationSourceType.DeploymentName, serializedAdditionalRawData: null, deploymentName, dimensions);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>. </summary>
        /// <param name="modelId"> The embedding model ID build inside the search service. Currently only supported by Elasticsearch®. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/> instance for mocking. </returns>
        public static OnYourDataModelIdVectorizationSource OnYourDataModelIdVectorizationSource(string modelId = null)
        {
            return new OnYourDataModelIdVectorizationSource(OnYourDataVectorizationSourceType.ModelId, serializedAdditionalRawData: null, modelId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureCosmosDBChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Azure OpenAI CosmosDB chat extensions. </param>
        /// <returns> A new <see cref="OpenAI.AzureCosmosDBChatExtensionConfiguration"/> instance for mocking. </returns>
        public static AzureCosmosDBChatExtensionConfiguration AzureCosmosDBChatExtensionConfiguration(AzureCosmosDBChatExtensionParameters parameters = null)
        {
            return new AzureCosmosDBChatExtensionConfiguration(AzureChatExtensionType.AzureCosmosDB, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureCosmosDBChatExtensionParameters"/>. </summary>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="maxSearchQueries">
        /// The max number of rewritten queries should be send to search provider for one user message. If not specified,
        /// the system will decide the number of queries to send.
        /// </param>
        /// <param name="allowPartialResult">
        /// If specified as true, the system will allow partial search results to be used and the request fails if all the queries fail.
        /// If not specified, or specified as false, the request will fail if any search query fails.
        /// </param>
        /// <param name="includeContexts"> The included properties of the output context. If not specified, the default value is `citations` and `intent`. </param>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUsernameAndPasswordAuthenticationOptions"/>.
        /// </param>
        /// <param name="databaseName"> The MongoDB vCore database name to use with Azure Cosmos DB. </param>
        /// <param name="containerName"> The name of the Azure Cosmos DB resource container. </param>
        /// <param name="indexName"> The MongoDB vCore index name to use with Azure Cosmos DB. </param>
        /// <param name="fieldMappingOptions"> Customized field mapping behavior to use when interacting with the search index. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/>, <see cref="OnYourDataIntegratedVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AzureCosmosDBChatExtensionParameters"/> instance for mocking. </returns>
        public static AzureCosmosDBChatExtensionParameters AzureCosmosDBChatExtensionParameters(int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, int? maxSearchQueries = null, bool? allowPartialResult = null, IEnumerable<OnYourDataContextProperty> includeContexts = null, OnYourDataAuthenticationOptions authentication = null, string databaseName = null, string containerName = null, string indexName = null, AzureCosmosDBFieldMappingOptions fieldMappingOptions = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            includeContexts ??= new List<OnYourDataContextProperty>();

            return new AzureCosmosDBChatExtensionParameters(
                documentCount,
                shouldRestrictResultScope,
                strictness,
                maxSearchQueries,
                allowPartialResult,
                includeContexts?.ToList(),
                authentication,
                databaseName,
                containerName,
                indexName,
                fieldMappingOptions,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ElasticsearchChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Elasticsearch®. </param>
        /// <returns> A new <see cref="OpenAI.ElasticsearchChatExtensionConfiguration"/> instance for mocking. </returns>
        public static ElasticsearchChatExtensionConfiguration ElasticsearchChatExtensionConfiguration(ElasticsearchChatExtensionParameters parameters = null)
        {
            return new ElasticsearchChatExtensionConfiguration(AzureChatExtensionType.Elasticsearch, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ElasticsearchChatExtensionParameters"/>. </summary>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="maxSearchQueries">
        /// The max number of rewritten queries should be send to search provider for one user message. If not specified,
        /// the system will decide the number of queries to send.
        /// </param>
        /// <param name="allowPartialResult">
        /// If specified as true, the system will allow partial search results to be used and the request fails if all the queries fail.
        /// If not specified, or specified as false, the request will fail if any search query fails.
        /// </param>
        /// <param name="includeContexts"> The included properties of the output context. If not specified, the default value is `citations` and `intent`. </param>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUsernameAndPasswordAuthenticationOptions"/>.
        /// </param>
        /// <param name="endpoint"> The endpoint of Elasticsearch®. </param>
        /// <param name="indexName"> The index name of Elasticsearch®. </param>
        /// <param name="fieldMappingOptions"> The index field mapping options of Elasticsearch®. </param>
        /// <param name="queryType"> The query type of Elasticsearch®. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/>, <see cref="OnYourDataIntegratedVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ElasticsearchChatExtensionParameters"/> instance for mocking. </returns>
        public static ElasticsearchChatExtensionParameters ElasticsearchChatExtensionParameters(int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, int? maxSearchQueries = null, bool? allowPartialResult = null, IEnumerable<OnYourDataContextProperty> includeContexts = null, OnYourDataAuthenticationOptions authentication = null, Uri endpoint = null, string indexName = null, ElasticsearchIndexFieldMappingOptions fieldMappingOptions = null, ElasticsearchQueryType? queryType = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            includeContexts ??= new List<OnYourDataContextProperty>();

            return new ElasticsearchChatExtensionParameters(
                documentCount,
                shouldRestrictResultScope,
                strictness,
                maxSearchQueries,
                allowPartialResult,
                includeContexts?.ToList(),
                authentication,
                endpoint,
                indexName,
                fieldMappingOptions,
                queryType,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.MongoDBChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters for the MongoDB chat extension. </param>
        /// <returns> A new <see cref="OpenAI.MongoDBChatExtensionConfiguration"/> instance for mocking. </returns>
        public static MongoDBChatExtensionConfiguration MongoDBChatExtensionConfiguration(MongoDBChatExtensionParameters parameters = null)
        {
            return new MongoDBChatExtensionConfiguration(AzureChatExtensionType.MongoDB, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.MongoDBChatExtensionParameters"/>. </summary>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="maxSearchQueries">
        /// The max number of rewritten queries should be send to search provider for one user message. If not specified,
        /// the system will decide the number of queries to send.
        /// </param>
        /// <param name="allowPartialResult">
        /// If specified as true, the system will allow partial search results to be used and the request fails if all the queries fail.
        /// If not specified, or specified as false, the request will fail if any search query fails.
        /// </param>
        /// <param name="includeContexts"> The included properties of the output context. If not specified, the default value is `citations` and `intent`. </param>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// </param>
        /// <param name="endpoint"> The endpoint name for MongoDB. </param>
        /// <param name="collectionName"> The collection name for MongoDB. </param>
        /// <param name="databaseName"> The database name for MongoDB. </param>
        /// <param name="appName"> The app name for MongoDB. </param>
        /// <param name="indexName"> The name of the MongoDB index. </param>
        /// <param name="fieldsMapping">
        /// Field mappings to apply to data used by the MongoDB data source.
        /// Note that content and vector field mappings are required for MongoDB.
        /// </param>
        /// <param name="embeddingDependency"> The vectorization source to use with the MongoDB chat extension. </param>
        /// <returns> A new <see cref="OpenAI.MongoDBChatExtensionParameters"/> instance for mocking. </returns>
        public static MongoDBChatExtensionParameters MongoDBChatExtensionParameters(int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, int? maxSearchQueries = null, bool? allowPartialResult = null, IEnumerable<OnYourDataContextProperty> includeContexts = null, OnYourDataUsernameAndPasswordAuthenticationOptions authentication = null, string endpoint = null, string collectionName = null, string databaseName = null, string appName = null, string indexName = null, MongoDBChatExtensionParametersFieldsMapping fieldsMapping = null, BinaryData embeddingDependency = null)
        {
            includeContexts ??= new List<OnYourDataContextProperty>();

            return new MongoDBChatExtensionParameters(
                documentCount,
                shouldRestrictResultScope,
                strictness,
                maxSearchQueries,
                allowPartialResult,
                includeContexts?.ToList(),
                authentication,
                endpoint,
                collectionName,
                databaseName,
                appName,
                indexName,
                fieldsMapping,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.PineconeChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Azure OpenAI chat extensions. </param>
        /// <returns> A new <see cref="OpenAI.PineconeChatExtensionConfiguration"/> instance for mocking. </returns>
        public static PineconeChatExtensionConfiguration PineconeChatExtensionConfiguration(PineconeChatExtensionParameters parameters = null)
        {
            return new PineconeChatExtensionConfiguration(AzureChatExtensionType.Pinecone, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.PineconeChatExtensionParameters"/>. </summary>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="maxSearchQueries">
        /// The max number of rewritten queries should be send to search provider for one user message. If not specified,
        /// the system will decide the number of queries to send.
        /// </param>
        /// <param name="allowPartialResult">
        /// If specified as true, the system will allow partial search results to be used and the request fails if all the queries fail.
        /// If not specified, or specified as false, the request will fail if any search query fails.
        /// </param>
        /// <param name="includeContexts"> The included properties of the output context. If not specified, the default value is `citations` and `intent`. </param>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUsernameAndPasswordAuthenticationOptions"/>.
        /// </param>
        /// <param name="environmentName"> The environment name of Pinecone. </param>
        /// <param name="indexName"> The name of the Pinecone database index. </param>
        /// <param name="fieldMappingOptions"> Customized field mapping behavior to use when interacting with the search index. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/>, <see cref="OnYourDataIntegratedVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.PineconeChatExtensionParameters"/> instance for mocking. </returns>
        public static PineconeChatExtensionParameters PineconeChatExtensionParameters(int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, int? maxSearchQueries = null, bool? allowPartialResult = null, IEnumerable<OnYourDataContextProperty> includeContexts = null, OnYourDataAuthenticationOptions authentication = null, string environmentName = null, string indexName = null, PineconeFieldMappingOptions fieldMappingOptions = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            includeContexts ??= new List<OnYourDataContextProperty>();

            return new PineconeChatExtensionParameters(
                documentCount,
                shouldRestrictResultScope,
                strictness,
                maxSearchQueries,
                allowPartialResult,
                includeContexts?.ToList(),
                authentication,
                environmentName,
                indexName,
                fieldMappingOptions,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletionsJsonSchemaResponseFormat"/>. </summary>
        /// <param name="jsonSchema"></param>
        /// <returns> A new <see cref="OpenAI.ChatCompletionsJsonSchemaResponseFormat"/> instance for mocking. </returns>
        public static ChatCompletionsJsonSchemaResponseFormat ChatCompletionsJsonSchemaResponseFormat(ChatCompletionsJsonSchemaResponseFormatJsonSchema jsonSchema = null)
        {
            return new ChatCompletionsJsonSchemaResponseFormat("json_schema", serializedAdditionalRawData: null, jsonSchema);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletionsJsonSchemaResponseFormatJsonSchema"/>. </summary>
        /// <param name="description"> A description of what the response format is for, used by the model to determine how to respond in the format. </param>
        /// <param name="name"> The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64. </param>
        /// <param name="schema"></param>
        /// <param name="strict"> Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the `schema` field. Only a subset of JSON Schema is supported when `strict` is `true`. To learn more, read the [Structured Outputs guide](/docs/guides/structured-outputs). </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletionsJsonSchemaResponseFormatJsonSchema"/> instance for mocking. </returns>
        public static ChatCompletionsJsonSchemaResponseFormatJsonSchema ChatCompletionsJsonSchemaResponseFormatJsonSchema(string description = null, string name = null, BinaryData schema = null, bool? strict = null)
        {
            return new ChatCompletionsJsonSchemaResponseFormatJsonSchema(description, name, schema, strict, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletionsFunctionToolDefinition"/>. </summary>
        /// <param name="function"> The function definition details for the function tool. </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletionsFunctionToolDefinition"/> instance for mocking. </returns>
        public static ChatCompletionsFunctionToolDefinition ChatCompletionsFunctionToolDefinition(ChatCompletionsFunctionToolDefinitionFunction function = null)
        {
            return new ChatCompletionsFunctionToolDefinition("function", serializedAdditionalRawData: null, function);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletionsFunctionToolDefinitionFunction"/>. </summary>
        /// <param name="description"> A description of what the function does, used by the model to choose when and how to call the function. </param>
        /// <param name="name"> The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64. </param>
        /// <param name="parameters"></param>
        /// <param name="strict"> Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](docs/guides/function-calling). </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletionsFunctionToolDefinitionFunction"/> instance for mocking. </returns>
        public static ChatCompletionsFunctionToolDefinitionFunction ChatCompletionsFunctionToolDefinitionFunction(string description = null, string name = null, BinaryData parameters = null, bool? strict = null)
        {
            return new ChatCompletionsFunctionToolDefinitionFunction(description, name, parameters, strict, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletionsNamedFunctionToolSelection"/>. </summary>
        /// <param name="function"> The function that should be called. </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletionsNamedFunctionToolSelection"/> instance for mocking. </returns>
        public static ChatCompletionsNamedFunctionToolSelection ChatCompletionsNamedFunctionToolSelection(ChatCompletionsFunctionToolSelection function = null)
        {
            return new ChatCompletionsNamedFunctionToolSelection("function", serializedAdditionalRawData: null, function);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.PredictionContent"/>. </summary>
        /// <param name="type">
        /// The type of the predicted content you want to provide. This type is
        /// currently always `content`.
        /// </param>
        /// <param name="content">
        /// The content that should be matched when generating a model response.
        /// If generated tokens would match this content, the entire model response
        /// can be returned much more quickly.
        /// </param>
        /// <returns> A new <see cref="OpenAI.PredictionContent"/> instance for mocking. </returns>
        public static PredictionContent PredictionContent(PredictionContentType type = default, BinaryData content = null)
        {
            return new PredictionContent(type, content, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletions"/>. </summary>
        /// <param name="id"> A unique identifier associated with this chat completions response. </param>
        /// <param name="created">
        /// The first timestamp associated with generation activity for this completions response,
        /// represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
        /// </param>
        /// <param name="choices">
        /// The collection of completions choices associated with this completions response.
        /// Generally, `n` choices are generated per provided prompt with a default value of 1.
        /// Token limits and other settings may limit the number of choices generated.
        /// </param>
        /// <param name="model"> The model name used for this completions request. </param>
        /// <param name="promptFilterResults">
        /// Content filtering results for zero or more prompts in the request. In a streaming request,
        /// results for different prompts may arrive at different times or in different orders.
        /// </param>
        /// <param name="systemFingerprint">
        /// Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that
        /// might impact determinism.
        /// </param>
        /// <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletions"/> instance for mocking. </returns>
        public static ChatCompletions ChatCompletions(string id = null, DateTimeOffset created = default, IEnumerable<ChatChoice> choices = null, string model = null, IEnumerable<ContentFilterResultsForPrompt> promptFilterResults = null, string systemFingerprint = null, CompletionsUsage usage = null)
        {
            choices ??= new List<ChatChoice>();
            promptFilterResults ??= new List<ContentFilterResultsForPrompt>();

            return new ChatCompletions(
                id,
                created,
                choices?.ToList(),
                model,
                promptFilterResults?.ToList(),
                systemFingerprint,
                usage,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatChoice"/>. </summary>
        /// <param name="message"> The chat message for a given chat completions prompt. </param>
        /// <param name="logProbabilityInfo"> The log probability information for this choice, as enabled via the 'logprobs' request option. </param>
        /// <param name="index"> The ordered index associated with this chat completions choice. </param>
        /// <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
        /// <param name="internalStreamingDeltaMessage"> The delta message content for a streaming response. </param>
        /// <param name="contentFilterResults">
        /// Information about the content filtering category (hate, sexual, violence, self_harm), if it
        /// has been detected, as well as the severity level (very_low, low, medium, high-scale that
        /// determines the intensity and risk level of harmful content) and if it has been filtered or not.
        /// </param>
        /// <param name="enhancements">
        /// Represents the output results of Azure OpenAI enhancements to chat completions, as configured via the matching input
        /// provided in the request. This supplementary information is only available when using Azure OpenAI and only when the
        /// request is configured to use enhancements.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ChatChoice"/> instance for mocking. </returns>
        public static ChatChoice ChatChoice(ChatResponseMessage message = null, ChatChoiceLogProbabilityInfo logProbabilityInfo = null, int index = default, CompletionsFinishReason? finishReason = null, ChatResponseMessage internalStreamingDeltaMessage = null, ContentFilterResultsForChoice contentFilterResults = null, AzureChatEnhancements enhancements = null)
        {
            return new ChatChoice(
                message,
                logProbabilityInfo,
                index,
                finishReason,
                internalStreamingDeltaMessage,
                contentFilterResults,
                enhancements,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatResponseMessage"/>. </summary>
        /// <param name="role"> The chat role associated with the message. </param>
        /// <param name="refusal"> The refusal message generated by the model. </param>
        /// <param name="content"> The content of the message. </param>
        /// <param name="toolCalls">
        /// The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// Please note <see cref="ChatCompletionsToolCall"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ChatCompletionsFunctionToolCall"/>.
        /// </param>
        /// <param name="functionCall">
        /// The function call that must be resolved and have its output appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// </param>
        /// <param name="audio">
        /// If the audio output modality is requested, this object contains data
        /// about the audio response from the model.
        /// </param>
        /// <param name="azureExtensionsContext">
        /// If Azure OpenAI chat extensions are configured, this array represents the incremental steps performed by those
        /// extensions while processing the chat completions request.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ChatResponseMessage"/> instance for mocking. </returns>
        public static ChatResponseMessage ChatResponseMessage(ChatRole role = default, string refusal = null, string content = null, IEnumerable<ChatCompletionsToolCall> toolCalls = null, FunctionCall functionCall = null, AudioResponseData audio = null, AzureChatExtensionsMessageContext azureExtensionsContext = null)
        {
            toolCalls ??= new List<ChatCompletionsToolCall>();

            return new ChatResponseMessage(
                role,
                refusal,
                content,
                toolCalls?.ToList(),
                functionCall,
                audio,
                azureExtensionsContext,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioResponseData"/>. </summary>
        /// <param name="id"> Unique identifier for this audio response. </param>
        /// <param name="expiresAt">
        /// The Unix timestamp (in seconds) for when this audio response
        /// will no longer be accessible on the server for use in multi-turn
        /// conversations.
        /// </param>
        /// <param name="data">
        /// Base64 encoded audio bytes generated by the model, in the format
        /// specified in the request.
        /// </param>
        /// <param name="transcript"> Transcript of the audio generated by the model. </param>
        /// <returns> A new <see cref="OpenAI.AudioResponseData"/> instance for mocking. </returns>
        public static AudioResponseData AudioResponseData(string id = null, DateTimeOffset expiresAt = default, string data = null, string transcript = null)
        {
            return new AudioResponseData(id, expiresAt, data, transcript, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatExtensionsMessageContext"/>. </summary>
        /// <param name="citations">
        ///   The contextual information associated with the Azure chat extensions used for a chat completions request.
        ///   These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the
        ///   course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat
        ///   extensions.
        /// </param>
        /// <param name="intent"> The detected intent from the chat history, used to pass to the next turn to carry over the context. </param>
        /// <param name="allRetrievedDocuments"> All the retrieved documents. </param>
        /// <returns> A new <see cref="OpenAI.AzureChatExtensionsMessageContext"/> instance for mocking. </returns>
        public static AzureChatExtensionsMessageContext AzureChatExtensionsMessageContext(IEnumerable<AzureChatExtensionDataSourceResponseCitation> citations = null, string intent = null, IEnumerable<AzureChatExtensionRetrievedDocument> allRetrievedDocuments = null)
        {
            citations ??= new List<AzureChatExtensionDataSourceResponseCitation>();
            allRetrievedDocuments ??= new List<AzureChatExtensionRetrievedDocument>();

            return new AzureChatExtensionsMessageContext(citations?.ToList(), intent, allRetrievedDocuments?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatExtensionDataSourceResponseCitation"/>. </summary>
        /// <param name="content"> The content of the citation. </param>
        /// <param name="title"> The title of the citation. </param>
        /// <param name="url"> The URL of the citation. </param>
        /// <param name="filepath"> The file path of the citation. </param>
        /// <param name="chunkId"> The chunk ID of the citation. </param>
        /// <param name="rerankScore"> The rerank score of the retrieved document. </param>
        /// <returns> A new <see cref="OpenAI.AzureChatExtensionDataSourceResponseCitation"/> instance for mocking. </returns>
        public static AzureChatExtensionDataSourceResponseCitation AzureChatExtensionDataSourceResponseCitation(string content = null, string title = null, string url = null, string filepath = null, string chunkId = null, double? rerankScore = null)
        {
            return new AzureChatExtensionDataSourceResponseCitation(
                content,
                title,
                url,
                filepath,
                chunkId,
                rerankScore,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatExtensionRetrievedDocument"/>. </summary>
        /// <param name="content"> The content of the citation. </param>
        /// <param name="title"> The title of the citation. </param>
        /// <param name="url"> The URL of the citation. </param>
        /// <param name="filepath"> The file path of the citation. </param>
        /// <param name="chunkId"> The chunk ID of the citation. </param>
        /// <param name="rerankScore"> The rerank score of the retrieved document. </param>
        /// <param name="searchQueries"> The search queries used to retrieve the document. </param>
        /// <param name="dataSourceIndex"> The index of the data source. </param>
        /// <param name="originalSearchScore"> The original search score of the retrieved document. </param>
        /// <param name="filterReason">
        /// Represents the rationale for filtering the document. If the document does not undergo filtering,
        /// this field will remain unset.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AzureChatExtensionRetrievedDocument"/> instance for mocking. </returns>
        public static AzureChatExtensionRetrievedDocument AzureChatExtensionRetrievedDocument(string content = null, string title = null, string url = null, string filepath = null, string chunkId = null, double? rerankScore = null, IEnumerable<string> searchQueries = null, int dataSourceIndex = default, double? originalSearchScore = null, AzureChatExtensionRetrieveDocumentFilterReason? filterReason = null)
        {
            searchQueries ??= new List<string>();

            return new AzureChatExtensionRetrievedDocument(
                content,
                title,
                url,
                filepath,
                chunkId,
                rerankScore,
                searchQueries?.ToList(),
                dataSourceIndex,
                originalSearchScore,
                filterReason,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatChoiceLogProbabilityInfo"/>. </summary>
        /// <param name="tokenLogProbabilityResults"> The list of log probability information entries for the choice's message content tokens, as requested via the 'logprobs' option. </param>
        /// <param name="refusal"> The list of log probability information entries for the choice's message refusal message tokens, as requested via the 'logprobs' option. </param>
        /// <returns> A new <see cref="OpenAI.ChatChoiceLogProbabilityInfo"/> instance for mocking. </returns>
        public static ChatChoiceLogProbabilityInfo ChatChoiceLogProbabilityInfo(IEnumerable<ChatTokenLogProbabilityResult> tokenLogProbabilityResults = null, IEnumerable<ChatTokenLogProbabilityResult> refusal = null)
        {
            tokenLogProbabilityResults ??= new List<ChatTokenLogProbabilityResult>();
            refusal ??= new List<ChatTokenLogProbabilityResult>();

            return new ChatChoiceLogProbabilityInfo(tokenLogProbabilityResults?.ToList(), refusal?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatTokenLogProbabilityResult"/>. </summary>
        /// <param name="token"> The message content token. </param>
        /// <param name="logProbability"> The log probability of the message content token. </param>
        /// <param name="utf8ByteValues"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is no bytes representation for the token. </param>
        /// <param name="topLogProbabilityEntries"> The list of most likely tokens and their log probability information, as requested via 'top_logprobs'. </param>
        /// <returns> A new <see cref="OpenAI.ChatTokenLogProbabilityResult"/> instance for mocking. </returns>
        public static ChatTokenLogProbabilityResult ChatTokenLogProbabilityResult(string token = null, float logProbability = default, IEnumerable<int> utf8ByteValues = null, IEnumerable<ChatTokenLogProbabilityInfo> topLogProbabilityEntries = null)
        {
            utf8ByteValues ??= new List<int>();
            topLogProbabilityEntries ??= new List<ChatTokenLogProbabilityInfo>();

            return new ChatTokenLogProbabilityResult(token, logProbability, utf8ByteValues?.ToList(), topLogProbabilityEntries?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatTokenLogProbabilityInfo"/>. </summary>
        /// <param name="token"> The message content token. </param>
        /// <param name="logProbability"> The log probability of the message content token. </param>
        /// <param name="utf8ByteValues"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is no bytes representation for the token. </param>
        /// <returns> A new <see cref="OpenAI.ChatTokenLogProbabilityInfo"/> instance for mocking. </returns>
        public static ChatTokenLogProbabilityInfo ChatTokenLogProbabilityInfo(string token = null, float logProbability = default, IEnumerable<int> utf8ByteValues = null)
        {
            utf8ByteValues ??= new List<int>();

            return new ChatTokenLogProbabilityInfo(token, logProbability, utf8ByteValues?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatEnhancements"/>. </summary>
        /// <param name="grounding"> The grounding enhancement that returns the bounding box of the objects detected in the image. </param>
        /// <returns> A new <see cref="OpenAI.AzureChatEnhancements"/> instance for mocking. </returns>
        public static AzureChatEnhancements AzureChatEnhancements(AzureGroundingEnhancement grounding = null)
        {
            return new AzureChatEnhancements(grounding, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancement"/>. </summary>
        /// <param name="lines"> The lines of text detected by the grounding enhancement. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancement"/> instance for mocking. </returns>
        public static AzureGroundingEnhancement AzureGroundingEnhancement(IEnumerable<AzureGroundingEnhancementLine> lines = null)
        {
            lines ??= new List<AzureGroundingEnhancementLine>();

            return new AzureGroundingEnhancement(lines?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancementLine"/>. </summary>
        /// <param name="text"> The text within the line. </param>
        /// <param name="spans"> An array of spans that represent detected objects and its bounding box information. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancementLine"/> instance for mocking. </returns>
        public static AzureGroundingEnhancementLine AzureGroundingEnhancementLine(string text = null, IEnumerable<AzureGroundingEnhancementLineSpan> spans = null)
        {
            spans ??= new List<AzureGroundingEnhancementLineSpan>();

            return new AzureGroundingEnhancementLine(text, spans?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancementLineSpan"/>. </summary>
        /// <param name="text"> The text content of the span that represents the detected object. </param>
        /// <param name="offset">
        /// The character offset within the text where the span begins. This offset is defined as the position of the first
        /// character of the span, counting from the start of the text as Unicode codepoints.
        /// </param>
        /// <param name="length"> The length of the span in characters, measured in Unicode codepoints. </param>
        /// <param name="polygon"> An array of objects representing points in the polygon that encloses the detected object. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancementLineSpan"/> instance for mocking. </returns>
        public static AzureGroundingEnhancementLineSpan AzureGroundingEnhancementLineSpan(string text = null, int offset = default, int length = default, IEnumerable<AzureGroundingEnhancementCoordinatePoint> polygon = null)
        {
            polygon ??= new List<AzureGroundingEnhancementCoordinatePoint>();

            return new AzureGroundingEnhancementLineSpan(text, offset, length, polygon?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancementCoordinatePoint"/>. </summary>
        /// <param name="x"> The x-coordinate (horizontal axis) of the point. </param>
        /// <param name="y"> The y-coordinate (vertical axis) of the point. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancementCoordinatePoint"/> instance for mocking. </returns>
        public static AzureGroundingEnhancementCoordinatePoint AzureGroundingEnhancementCoordinatePoint(float x = default, float y = default)
        {
            return new AzureGroundingEnhancementCoordinatePoint(x, y, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerations"/>. </summary>
        /// <param name="created">
        /// A timestamp representing when this operation was started.
        /// Expressed in seconds since the Unix epoch of 1970-01-01T00:00:00+0000.
        /// </param>
        /// <param name="data"> The images generated by the operation. </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerations"/> instance for mocking. </returns>
        public static ImageGenerations ImageGenerations(DateTimeOffset created = default, IEnumerable<ImageGenerationData> data = null)
        {
            data ??= new List<ImageGenerationData>();

            return new ImageGenerations(created, data?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerationData"/>. </summary>
        /// <param name="url"> The URL that provides temporary access to download the generated image. </param>
        /// <param name="base64Data"> The complete data for an image, represented as a base64-encoded string. </param>
        /// <param name="contentFilterResults"> Information about the content filtering results. </param>
        /// <param name="revisedPrompt">
        /// The final prompt used by the model to generate the image.
        /// Only provided with dall-3-models and only when revisions were made to the prompt.
        /// </param>
        /// <param name="promptFilterResults">
        /// Information about the content filtering category (hate, sexual, violence, self_harm), if
        /// it has been detected, as well as the severity level (very_low, low, medium, high-scale
        /// that determines the intensity and risk level of harmful content) and if it has been
        /// filtered or not. Information about jailbreak content and profanity, if it has been detected,
        /// and if it has been filtered or not. And information about customer block list, if it has
        /// been filtered and its id.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerationData"/> instance for mocking. </returns>
        public static ImageGenerationData ImageGenerationData(Uri url = null, string base64Data = null, ImageGenerationContentFilterResults contentFilterResults = null, string revisedPrompt = null, ImageGenerationPromptFilterResults promptFilterResults = null)
        {
            return new ImageGenerationData(
                url,
                base64Data,
                contentFilterResults,
                revisedPrompt,
                promptFilterResults,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerationContentFilterResults"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerationContentFilterResults"/> instance for mocking. </returns>
        public static ImageGenerationContentFilterResults ImageGenerationContentFilterResults(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null)
        {
            return new ImageGenerationContentFilterResults(sexual, violence, hate, selfHarm, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerationPromptFilterResults"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <param name="profanity"> Describes whether profanity was detected. </param>
        /// <param name="jailbreak"> Whether a jailbreak attempt was detected in the prompt. </param>
        /// <param name="customBlocklists"> Information about customer block lists and if something was detected the associated list ID. </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerationPromptFilterResults"/> instance for mocking. </returns>
        public static ImageGenerationPromptFilterResults ImageGenerationPromptFilterResults(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null, ContentFilterDetectionResult profanity = null, ContentFilterDetectionResult jailbreak = null, ContentFilterDetailedResults customBlocklists = null)
        {
            return new ImageGenerationPromptFilterResults(
                sexual,
                violence,
                hate,
                selfHarm,
                profanity,
                jailbreak,
                customBlocklists,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.SpeechGenerationOptions"/>. </summary>
        /// <param name="input"> The text to generate audio for. The maximum length is 4096 characters. </param>
        /// <param name="voice"> The voice to use for text-to-speech. </param>
        /// <param name="responseFormat"> The audio output format for the spoken text. By default, the MP3 format will be used. </param>
        /// <param name="speed"> The speed of speech for generated audio. Values are valid in the range from 0.25 to 4.0, with 1.0 the default and higher values corresponding to faster speech. </param>
        /// <param name="deploymentName"> The model to use for this text-to-speech request. </param>
        /// <returns> A new <see cref="OpenAI.SpeechGenerationOptions"/> instance for mocking. </returns>
        public static SpeechGenerationOptions SpeechGenerationOptions(string input = null, SpeechVoice voice = default, SpeechGenerationResponseFormat? responseFormat = null, float? speed = null, string deploymentName = null)
        {
            return new SpeechGenerationOptions(
                input,
                voice,
                responseFormat,
                speed,
                deploymentName,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.FileListResponse"/>. </summary>
        /// <param name="object"> The object type, which is always 'list'. </param>
        /// <param name="data"> The files returned for the request. </param>
        /// <returns> A new <see cref="OpenAI.FileListResponse"/> instance for mocking. </returns>
        public static FileListResponse FileListResponse(FileListResponseObject @object = default, IEnumerable<OpenAIFile> data = null)
        {
            data ??= new List<OpenAIFile>();

            return new FileListResponse(@object, data?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OpenAIFile"/>. </summary>
        /// <param name="object"> The object type, which is always 'file'. </param>
        /// <param name="id"> The identifier, which can be referenced in API endpoints. </param>
        /// <param name="bytes"> The size of the file, in bytes. </param>
        /// <param name="filename"> The name of the file. </param>
        /// <param name="createdAt"> The Unix timestamp, in seconds, representing when this object was created. </param>
        /// <param name="purpose"> The intended purpose of a file. </param>
        /// <param name="status"> The state of the file. This field is available in Azure OpenAI only. </param>
        /// <param name="statusDetails"> The error message with details in case processing of this file failed. This field is available in Azure OpenAI only. </param>
        /// <returns> A new <see cref="OpenAI.OpenAIFile"/> instance for mocking. </returns>
        public static OpenAIFile OpenAIFile(OpenAIFileObject @object = default, string id = null, int bytes = default, string filename = null, DateTimeOffset createdAt = default, FilePurpose purpose = default, FileState? status = null, string statusDetails = null)
        {
            return new OpenAIFile(
                @object,
                id,
                bytes,
                filename,
                createdAt,
                purpose,
                status,
                statusDetails,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.FileDeletionStatus"/>. </summary>
        /// <param name="id"> The ID of the resource specified for deletion. </param>
        /// <param name="deleted"> A value indicating whether deletion was successful. </param>
        /// <param name="object"> The object type, which is always 'file'. </param>
        /// <returns> A new <see cref="OpenAI.FileDeletionStatus"/> instance for mocking. </returns>
        public static FileDeletionStatus FileDeletionStatus(string id = null, bool deleted = default, FileDeletionStatusObject @object = default)
        {
            return new FileDeletionStatus(id, deleted, @object, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OpenAIPageableListOfBatch"/>. </summary>
        /// <param name="object"> The object type, which is always list. </param>
        /// <param name="data"> The requested list of items. </param>
        /// <param name="firstId"> The first ID represented in this list. </param>
        /// <param name="lastId"> The last ID represented in this list. </param>
        /// <param name="hasMore"> A value indicating whether there are additional values available not captured in this list. </param>
        /// <returns> A new <see cref="OpenAI.OpenAIPageableListOfBatch"/> instance for mocking. </returns>
        public static OpenAIPageableListOfBatch OpenAIPageableListOfBatch(OpenAIPageableListOfBatchObject @object = default, IEnumerable<OpenAI.Batch> data = null, string firstId = null, string lastId = null, bool? hasMore = null)
        {
            data ??= new List<OpenAI.Batch>();

            return new OpenAIPageableListOfBatch(
                @object,
                data?.ToList(),
                firstId,
                lastId,
                hasMore,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.BatchCreateRequest"/>. </summary>
        /// <param name="endpoint"> The API endpoint used by the batch. </param>
        /// <param name="inputFileId"> The ID of the input file for the batch. </param>
        /// <param name="completionWindow"> The time frame within which the batch should be processed. </param>
        /// <param name="metadata"> A set of key-value pairs that can be attached to the batch. This can be useful for storing additional information about the batch in a structured format. </param>
        /// <returns> A new <see cref="OpenAI.BatchCreateRequest"/> instance for mocking. </returns>
        public static BatchCreateRequest BatchCreateRequest(string endpoint = null, string inputFileId = null, string completionWindow = null, IDictionary<string, string> metadata = null)
        {
            metadata ??= new Dictionary<string, string>();

            return new BatchCreateRequest(endpoint, inputFileId, completionWindow, metadata, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.Upload"/>. </summary>
        /// <param name="id"> The Upload unique identifier, which can be referenced in API endpoints. </param>
        /// <param name="createdAt"> The Unix timestamp (in seconds) for when the Upload was created. </param>
        /// <param name="filename"> The name of the file to be uploaded. </param>
        /// <param name="bytes"> The intended number of bytes to be uploaded. </param>
        /// <param name="purpose"> The intended purpose of the file. </param>
        /// <param name="status"> The status of the Upload. </param>
        /// <param name="expiresAt"> The Unix timestamp (in seconds) for when the Upload was created. </param>
        /// <param name="object"> The object type, which is always "upload". </param>
        /// <param name="file"> The ready File object after the Upload is completed. </param>
        /// <returns> A new <see cref="OpenAI.Upload"/> instance for mocking. </returns>
        public static Upload Upload(string id = null, DateTimeOffset createdAt = default, string filename = null, long bytes = default, UploadPurpose purpose = default, UploadStatus status = default, DateTimeOffset expiresAt = default, UploadObject? @object = null, OpenAIFile file = null)
        {
            return new Upload(
                id,
                createdAt,
                filename,
                bytes,
                purpose,
                status,
                expiresAt,
                @object,
                file,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.UploadPart"/>. </summary>
        /// <param name="id"> The upload Part unique identifier, which can be referenced in API endpoints. </param>
        /// <param name="createdAt"> The Unix timestamp (in seconds) for when the Part was created. </param>
        /// <param name="uploadId"> The ID of the Upload object that this Part was added to. </param>
        /// <param name="object"> The object type, which is always `upload.part`. </param>
        /// <param name="azureBlockId"> Azure only field. </param>
        /// <returns> A new <see cref="OpenAI.UploadPart"/> instance for mocking. </returns>
        public static UploadPart UploadPart(string id = null, DateTimeOffset createdAt = default, string uploadId = null, UploadPartObject @object = default, string azureBlockId = null)
        {
            return new UploadPart(
                id,
                createdAt,
                uploadId,
                @object,
                azureBlockId,
                serializedAdditionalRawData: null);
        }
    }
}
